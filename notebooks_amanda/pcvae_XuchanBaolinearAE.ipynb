{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa84dc88",
   "metadata": {},
   "source": [
    "## Working on integration with PCVAE\n",
    "\n",
    "### Simplified code from \"Regularized linear autoencoders recover the principal components, eventually\"\n",
    "\n",
    "##### Compare to: https://github.com/XuchanBao/linear-ae/\n",
    "###### Here, I have simplfiied her code for the linear autoencoder with rotation and linear nested dropout autoencoder with expectation.\n",
    "###### The test runs use optimal parameters from the WandB sweep, and the output loss, distance to subspace, and distance to alignment with true singular vectors matches the output from her original code in the WandB sweep.\n",
    "\n",
    "#### Also note that rotation does not apply if not using SGD optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9a776a",
   "metadata": {},
   "source": [
    "#### IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e45124",
   "metadata": {},
   "source": [
    "#### Import custom libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3813468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "from pcmf import pcmf_full, path_plot, plot_ordercolor, plot_cluster_assignments\n",
    "from pcvae import get_weights as get_weights_pcvae\n",
    "# from pcvae import sparse_D as sparse_D_pcvae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1735663e",
   "metadata": {},
   "source": [
    "#### Import other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6216efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902c520c",
   "metadata": {},
   "source": [
    "#### DEFINE DATA LOADER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f7a5b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DEFINE DATA LOADER FUNCTIONS ####\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import numpy as np\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "class synthetic_Dataset(Dataset):\n",
    "    ''' Custom data class generated from PCMF synthetic data generator.. '''\n",
    "    def __init__(self, X, X_labels):\n",
    "        super(synthetic_Dataset,self).__init__()\n",
    "        self.X = X\n",
    "        self.X_labels = X_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_labels)\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        data = self.X[index]\n",
    "        data_label = self.X_labels[index]\n",
    "        return torch.tensor(data, dtype=torch.float32), torch.tensor(data_label, dtype=torch.float32)\n",
    "\n",
    "\n",
    "class DataGeneratorPPCA(Dataset):\n",
    "\n",
    "    def __init__(self, dims, hdims, min_sv=0.11, max_sv=5.0, sigma_sq=0.1, deterministic=True, total=10000):\n",
    "        self.dims = dims\n",
    "        self.hdims = hdims\n",
    "\n",
    "        self.eigs = min_sv + (max_sv - min_sv) * np.linspace(0, 1, hdims)\n",
    "        self.eigvectors = ortho_group.rvs(dims)[:, :hdims]\n",
    "        self.w = np.matmul(self.eigvectors, np.diag(np.sqrt(self.eigs - sigma_sq)))\n",
    "\n",
    "        self.sigma_sq = sigma_sq\n",
    "        self.sigma = np.sqrt(sigma_sq)\n",
    "\n",
    "        self.total = total\n",
    "        self.deterministic = deterministic\n",
    "        if self.deterministic:\n",
    "            self.z_sample = np.random.normal(size=(total, self.hdims))\n",
    "            self.x_sample = np.random.normal(np.matmul(self.z_sample, self.w.T), self.sigma).astype(np.float32)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.deterministic:\n",
    "            return self.x_sample[i]\n",
    "        else:\n",
    "            z_sample = np.random.normal(size=self.hdims)\n",
    "            return np.random.normal(self.w.dot(z_sample), self.sigma).astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return a large number for an epoch\n",
    "        return self.total\n",
    "\n",
    "\n",
    "class DataGeneratorPCA(Dataset):\n",
    "    def __init__(self, dims, hdims, min_sv=0.11, max_sv=5.0, total=10000, sv_list=None,\n",
    "                 load_data=None):\n",
    "        self.dims = dims\n",
    "        self.hdims = hdims\n",
    "\n",
    "        if load_data is None:\n",
    "            if isinstance(sv_list, list):\n",
    "                assert len(sv_list) == dims\n",
    "                self.full_eigs = np.array(sorted(sv_list, reverse=True))\n",
    "            else:\n",
    "                self.full_eigs = min_sv + (max_sv - min_sv) * np.linspace(1, 0, dims)\n",
    "            self.eigs = self.full_eigs[:hdims]\n",
    "\n",
    "            self.full_svs = np.sqrt(self.full_eigs)\n",
    "\n",
    "            self.full_eigvectors = ortho_group.rvs(dims)\n",
    "            self.eigvectors = self.full_eigvectors[:, :hdims]\n",
    "\n",
    "            self.total = total\n",
    "\n",
    "            self.full_z_sample = np.random.normal(size=(total, self.dims))\n",
    "            self.x_sample = (self.full_eigvectors @ np.diag(self.full_svs) @ self.full_z_sample.T).T.astype(np.float32)\n",
    "\n",
    "        else:\n",
    "            self.x_sample = load_data\n",
    "            u, s, vh = np.linalg.svd(self.x_sample.T, full_matrices=False)\n",
    "            self.eigs = s[:self.hdims]\n",
    "            self.eigvectors = u[:, :self.hdims]\n",
    "            self.total = len(self.x_sample)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.x_sample[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.x_sample.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00792a1f",
   "metadata": {},
   "source": [
    "#### DEFINE MODEL CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c82d6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DEFINE MODEL CLASSES ####\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    '''\n",
    "    Convert a scipy sparse matrix to a torch sparse tensor.\n",
    "    '''\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "def sparse_D_pcvae(n,p):\n",
    "    '''\n",
    "    Construct a sparse matrix, that when applied to a vector containing concatenated vectors\n",
    "    of coefficients b = [b_1 b_2 ... b_n] where each b_i is p=num_var long and there are\n",
    "    n = num_vec of them. Differences are taken between conformal elements (e.g. b_11 and b_21)\n",
    "    across all unique pairwise combinations of vectors.\n",
    "    '''\n",
    "    comb_list = list(combinations(range(n),2))\n",
    "    combs_arr = np.array(comb_list)\n",
    "    num_combs = combs_arr.shape[0]\n",
    "    data = np.ones_like(combs_arr)\n",
    "    data[:,1] *= -1\n",
    "    row = np.repeat(range(num_combs),2)\n",
    "    col = combs_arr.flatten()\n",
    "    D = csr_matrix((data.flatten(), (row, col)), shape=(num_combs, n))\n",
    "    return sparse_mx_to_torch_sparse_tensor(D)\n",
    "\n",
    "def convclust_penalty(recons, weights, wasserstein=False, q=2):\n",
    "    '''\n",
    "    Computes the differences between all rows of the output.\n",
    "    :return: (Tensor)\n",
    "    '''\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n,p = recons.shape        \n",
    "    D = sparse_D_pcvae(n,p).to(device)\n",
    "#         if wasserstein:\n",
    "#             recons = torch.sort(recons)[0]\n",
    "#     print('recons',recons.shape, 'weights',weights.shape, 'D',D.shape)\n",
    "    diffs = torch.norm(D.matmul(recons), q, dim=1)\n",
    "    return torch.norm(torch.mul(weights, diffs), 1)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from scipy.sparse import csr_matrix\n",
    "import secrets\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ModelConfig:\n",
    "    def __init__(self, model_name, model_type, model_class, input_dim, hidden_dim, init_scale, optim_class, lr,\n",
    "                 extra_model_args={}, extra_optim_args={}):\n",
    "        self.model_name = model_name\n",
    "        self.model_type = model_type\n",
    "        self.model_class = model_class\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.init_scale = init_scale\n",
    "        self.extra_model_args = extra_model_args\n",
    "\n",
    "        self.optim_class = optim_class\n",
    "        self.lr = lr\n",
    "        self.extra_optim_args = extra_optim_args\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = model_class(input_dim=input_dim, hidden_dim=hidden_dim, init_scale=init_scale, **extra_model_args).to(device)\n",
    "\n",
    "        self.optimizer = optim_class(self.model.parameters(), lr=lr, **extra_optim_args)\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.model_name\n",
    "\n",
    "    @property\n",
    "    def type(self):\n",
    "        return self.model_type\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        return self.optimizer\n",
    "\n",
    "class LinearAE(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim, hidden_dim, init_scale=0.001,\n",
    "                 weight_reg_type=None, l2_reg_list=None, cc_lambda=0.0, gauss_coef=1.0, neighbors=None):\n",
    "        super(LinearAE, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.encoder = nn.Linear(input_dim, hidden_dim, bias=False)\n",
    "        self.decoder = nn.Linear(hidden_dim, input_dim, bias=False)\n",
    "\n",
    "        self.weight_reg_type = weight_reg_type\n",
    "        self.l2_reg_scalar = None\n",
    "        self.l2_reg_list = l2_reg_list\n",
    "\n",
    "        self.encoder.weight.data.normal_(0.0, init_scale)\n",
    "        self.decoder.weight.data.normal_(0.0, init_scale)\n",
    "        \n",
    "        self.cc_weights = None\n",
    "        self.cc_lambda = cc_lambda\n",
    "        self.gauss_coef = gauss_coef\n",
    "        self.neighbors = neighbors\n",
    "        \n",
    "        # configure regularization parameters\n",
    "\n",
    "#         assert self.weight_reg_type is None or isinstance(self.l2_reg_list, list), \\\n",
    "#             \"l2_reg_list must be a list if weight_reg_type is not None\"\n",
    "\n",
    "# #         assert self.l2_reg_list is None or len(self.l2_reg_list) == hidden_dim, \\\n",
    "#             \"Length of l2_reg_list must match latent dimension\"\n",
    "\n",
    "        if weight_reg_type in (\"uniform_product\", \"uniform_sum\"):\n",
    "            self.l2_reg_scalar = l2_reg_list[0] ** 2    # more efficient to use scalar than diag_weights\n",
    "\n",
    "        elif weight_reg_type == \"non_uniform_sum\":\n",
    "            self.reg_weights = torch.tensor(\n",
    "                np.array(self.l2_reg_list).astype(np.float32)\n",
    "            )\n",
    "            self.diag_weights = nn.Parameter(torch.diag(self.reg_weights), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.weight_reg_type is 'convex_cluster':\n",
    "            if self.cc_weights is None:\n",
    "                print('Getting convex clustering weights.')\n",
    "                self.cc_weights = torch.from_numpy(get_weights_pcvae(x.detach().cpu().numpy().reshape(x.shape[0], \\\n",
    "                                                                                     np.prod(x.shape[1::])) , gauss_coef=self.gauss_coef, neighbors=self.neighbors) ).to(device)\n",
    "                print(self.cc_weights.shape)\n",
    "        return self.get_reconstruction_loss(x) + self._get_reg_loss(x)\n",
    "\n",
    "    def compute_trace_norm(self):\n",
    "        \"\"\"\n",
    "        Computes the trace norm of the autoencoder, as well as decoder and encoder individually\n",
    "        :return: trace_norm(W2W1), trace_norm(W1), trace_norm(W2)\n",
    "        \"\"\"\n",
    "        return torch.matmul(self.decoder.weight, self.encoder.weight).norm(p='nuc'), \\\n",
    "               self.encoder.weight.norm(p='nuc'), \\\n",
    "               self.decoder.weight.norm(p='nuc'),\n",
    "\n",
    "    def get_reconstruction_loss(self, x):\n",
    "        z = self.encoder(x)\n",
    "        recon = self.decoder(z)\n",
    "\n",
    "        recon_loss = torch.sum((x - recon) ** 2) / len(x)\n",
    "        return recon_loss\n",
    "\n",
    "    def get_reg_weights_np(self):\n",
    "        if self.weight_reg_type is None:\n",
    "            return np.zeros(self.hidden_dim)\n",
    "        return np.array(self.l2_reg_list)\n",
    "    \n",
    "\n",
    "    def _get_reg_loss(self, x):\n",
    "        # Standard L2 regularization, applied to W2W1 (product loss)\n",
    "        if self.weight_reg_type == 'uniform_product':\n",
    "            return self.l2_reg_scalar * (torch.norm(torch.matmul(self.decoder.weight, self.encoder.weight)) ** 2)\n",
    "\n",
    "        # Standard L2 regularization for encoder and decoder separately (sum loss)\n",
    "        elif self.weight_reg_type == 'uniform_sum':\n",
    "            # regularize both encoder and decoder\n",
    "            return self.l2_reg_scalar * (torch.norm(self.encoder.weight) ** 2 + torch.norm(self.decoder.weight) ** 2)\n",
    "\n",
    "        # non-uniform sum\n",
    "        elif self.weight_reg_type == 'non_uniform_sum':\n",
    "            return torch.norm(self.diag_weights @ self.encoder.weight) ** 2 \\\n",
    "                   + torch.norm(self.decoder.weight @ self.diag_weights) ** 2\n",
    "\n",
    "        # Do not apply regularization\n",
    "        elif self.weight_reg_type is None:\n",
    "            return 0.0\n",
    "\n",
    "        # Do not apply regularization\n",
    "        elif self.weight_reg_type is 'convex_cluster':\n",
    "            # Eulerian convex clustering loss\n",
    "            # cc_target needs to be the reconstruction\n",
    "            # need to get weights\n",
    "            recon = self.decoder(self.encoder(x)).data.detach().cpu() #.numpy()\n",
    "            convclust_loss = convclust_penalty(recon, self.cc_weights)\n",
    "#             print('convclust_loss:',convclust_loss,'cc_lambda*convclust_loss:',self.cc_lambda,self.cc_lambda*convclust_loss)\n",
    "            return self.cc_lambda*convclust_loss\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"weight_reg_type should be one of (uniform_product, uniform_sum, non_uniform_sum, None)\")\n",
    "            \n",
    "            \n",
    "class LinearAENestedDropout(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim, hidden_dim, init_scale=0.001, prior_probs=None, use_expectation=False):\n",
    "        super(LinearAENestedDropout, self).__init__()\n",
    "\n",
    "        self.use_expectation = use_expectation\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.encoder = nn.Linear(input_dim, hidden_dim, bias=False)\n",
    "        self.decoder = nn.Linear(hidden_dim, input_dim, bias=False)\n",
    "\n",
    "        self.encoder.weight.data.normal_(0.0, init_scale)\n",
    "        self.decoder.weight.data.normal_(0.0, init_scale)\n",
    "\n",
    "        if prior_probs is None:\n",
    "            # use geometric distribution\n",
    "            # p(b) = rho^b (1 - rho) (b = 0 ... k - 2)\n",
    "            # p(b = k-1) = 1 - sum(p(b), b < k-1)\n",
    "\n",
    "            self.geom_p = 0.9\n",
    "            prior_probs = [self.geom_p ** b * (1 - self.geom_p) for b in range(self.hidden_dim - 1)]\n",
    "            prior_probs.append(1.0 - sum(prior_probs))\n",
    "\n",
    "        self.prior_probs = torch.tensor(prior_probs)\n",
    "\n",
    "        cum_probs = [1. - sum(prior_probs[:i]) for i in range(self.hidden_dim)]\n",
    "        self.cum_probs = torch.tensor(cum_probs)\n",
    "        self.diag_expected_mask = nn.Parameter(torch.diag(self.cum_probs), requires_grad=False)\n",
    "        l_expected_mask = np.zeros((self.hidden_dim, self.hidden_dim))\n",
    "        for i in range(self.hidden_dim):\n",
    "            l_expected_mask[i, i] = cum_probs[i]\n",
    "            l_expected_mask[:i, i] = cum_probs[i]\n",
    "            l_expected_mask[i, :i] = cum_probs[i]\n",
    "        self.l_expected_mask = nn.Parameter(torch.from_numpy(l_expected_mask).float(), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_expectation:\n",
    "            tr_xtx = torch.norm(x) ** 2\n",
    "            w1_x = self.encoder(x).T        # (k, n)\n",
    "            tr_xt_w2_y = torch.trace(w1_x @ x @ self.decoder.weight @ self.diag_expected_mask)\n",
    "            w2t_w2_masked = (self.decoder.weight.T @ self.decoder.weight) * self.l_expected_mask\n",
    "            tr_yt_w2t_w2_y = torch.trace(w1_x @ w1_x.T @ w2t_w2_masked)\n",
    "\n",
    "            recon_loss = (tr_xtx - 2 * tr_xt_w2_y + tr_yt_w2t_w2_y) / len(x)\n",
    "        else:\n",
    "            hidden_units = self.encoder(x)\n",
    "            hidden_units = self._nested_dropout(hidden_units)\n",
    "            recon = self.decoder(hidden_units)\n",
    "\n",
    "            recon_loss = torch.sum((x - recon) ** 2) / len(x)\n",
    "        return recon_loss\n",
    "\n",
    "    def _nested_dropout(self, hidden_units):\n",
    "        prior_inds = torch.multinomial(self.prior_probs, len(hidden_units), replacement=True)\n",
    "        mask = torch.ones_like(hidden_units)\n",
    "        for hdim_i in range(1, self.hidden_dim):\n",
    "            drop_row_inds = (prior_inds < hdim_i).float()     # 1 if row is dropped, 0 if kept\n",
    "            mask[:, hdim_i] = 1 - drop_row_inds     # 1 if kept, 0 if dropped\n",
    "\n",
    "        masked_hidden_units = hidden_units * mask\n",
    "        return masked_hidden_units\n",
    "\n",
    "    def get_reconstruction_loss(self, x):\n",
    "        hidden_units = self.encoder(x)\n",
    "        recon = self.decoder(hidden_units)\n",
    "\n",
    "        recon_loss = torch.sum((x - recon) ** 2) / len(x)\n",
    "        return recon_loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdd0ba9",
   "metadata": {},
   "source": [
    "#### DEFINE MODEL TRAINING FUNCTION train_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "abffa7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DEFINE MODEL TRAINING FUNCTION train_models ####\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_models(data_loader, train_itr, metrics_dict, model_configs, eval_metrics_list=None):\n",
    "    for train_i in range(train_itr):\n",
    "        for x in data_loader:\n",
    "            x_cuda = x.to(device)\n",
    "\n",
    "            # ---- Optimize ----\n",
    "            losses = {}\n",
    "\n",
    "            model = model_config.get_model()\n",
    "            optimizer = model_config.get_optimizer()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = model(x_cuda)\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            if model_config.type == 'rotation':\n",
    "                # Rotation Augmented Gradient (RAG) \n",
    "                y = model.encoder.weight @ x_cuda.T\n",
    "                yy_t_norm = y @ y.T / float(len(x))\n",
    "                yy_t_upper = yy_t_norm - yy_t_norm.tril()\n",
    "                gamma = 0.5 * (yy_t_upper - yy_t_upper.T)\n",
    "\n",
    "                model.encoder.weight.grad -= gamma @ model.encoder.weight\n",
    "                model.decoder.weight.grad -= model.decoder.weight @ gamma.T\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            losses[model_config.name] = loss.item()\n",
    "\n",
    "        # ---- Log statistics ----\n",
    "        if train_i == 0 or (train_i + 1) % 10 == 0:\n",
    "            print(\"\".join([\"Iteration = {}, Losses: \".format(train_i + 1)]\n",
    "                          + [\"{} = {} \".format(key, val) for key, val in losses.items()]))\n",
    "                \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "3e703be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models_path(X_train, train_loader, model_config, lambda_path,\n",
    "                   epochs_per_lambda=5, neighbors=None):\n",
    "    ''' Train linear autoencoder (not setup currently for nested AE)'''\n",
    "    embeddings_list = []\n",
    "    encoder_weights_list = []\n",
    "    decoder_weights_list = []\n",
    "    reconstructions_list = []\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    for i, lambd in enumerate(lambda_path):         \n",
    "        # Update convex clustering penalty\n",
    "        model_config.get_model().cc_lambda = lambd\n",
    "        # Train model over epochs_per_lambda iterations\n",
    "        train_models(data_loader=train_loader, train_itr=epochs_per_lambda, model_configs=model_config, metrics_dict=None, eval_metrics_list=None)\n",
    "        \n",
    "        # Save encoder/decoder weights, encoded embeddings, and decoded reconstructions\n",
    "        model = model_config.get_model()\n",
    "        \n",
    "        encoder_weights_list.append(model.encoder.weight.data.detach().cpu().numpy())\n",
    "        decoder_weights_list.append(model.encoder.weight.data.detach().cpu().numpy())\n",
    "        embeddings_list.append(model.encoder(torch.tensor(X_train, dtype=torch.float32).to(device)).detach().cpu().numpy())\n",
    "        reconstructions_list.append(model.forward(torch.tensor(X_train, dtype=torch.float32))[0].data.detach().cpu().numpy())\n",
    "\n",
    "    return encoder_weights_list, decoder_weights_list, embeddings_list, reconstructions_list, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d5155",
   "metadata": {},
   "source": [
    "#### DEFINE EVALUATION METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5c7c976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_weight_tensor_from_seq(weight_seq):\n",
    "    if isinstance(weight_seq, nn.Linear):\n",
    "        return weight_seq.weight.detach()\n",
    "    elif isinstance(weight_seq, nn.Sequential):\n",
    "        weight_tensor = None\n",
    "        for layer in weight_seq:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer_weight = layer.weight.detach()\n",
    "                if weight_tensor is None:\n",
    "                    weight_tensor = layer_weight\n",
    "                else:\n",
    "                    weight_tensor = layer_weight @ weight_tensor\n",
    "            elif isinstance(layer, nn.BatchNorm1d):\n",
    "                bn_weight = layer.weight.detach()\n",
    "\n",
    "                # ignore bias\n",
    "\n",
    "                if weight_tensor is None:\n",
    "                    weight_tensor = torch.diag(bn_weight)\n",
    "                else:\n",
    "                    weight_tensor = torch.diag(bn_weight) @ weight_tensor\n",
    "            else:\n",
    "                raise ValueError(\"Layer type {} not supported!\".format(type(layer)))\n",
    "        return weight_tensor\n",
    "\n",
    "\n",
    "def metric_transpose_theorem(model):\n",
    "    \"\"\"\n",
    "    Metric for how close encoder and decoder.T are\n",
    "    :param model: LinearAE model\n",
    "    :return: ||W1 - W2^T||_F^2 / hidden_dim\n",
    "    \"\"\"\n",
    "    encoder_weight = get_weight_tensor_from_seq(model.encoder)\n",
    "    decoder_weight = get_weight_tensor_from_seq(model.decoder)\n",
    "\n",
    "    transpose_metric = torch.norm(encoder_weight - decoder_weight.T) ** 2\n",
    "    return transpose_metric.item() / float(model.hidden_dim)\n",
    "\n",
    "\n",
    "def metric_alignment(model, gt_eigvectors):\n",
    "    \"\"\"\n",
    "    Metric for alignment of decoder columns to ground truth eigenvectors\n",
    "    :param model: Linear AE model\n",
    "    :param gt_eigvectors: ground truth eigenvectors (input_dims,hidden_dims)\n",
    "    :return: sum_i (1 - max_j (cos(eigvector_i, normalized_decoder column_j)))\n",
    "    \"\"\"\n",
    "    decoder_weight = get_weight_tensor_from_seq(model.decoder)\n",
    "    decoder_np = decoder_weight.detach().cpu().numpy()\n",
    "\n",
    "    # normalize columns of gt_eigvectors\n",
    "    norm_gt_eigvectors = gt_eigvectors / np.linalg.norm(gt_eigvectors, axis=0)\n",
    "    # normalize columns of decoder\n",
    "    norm_decoder = decoder_np / (np.linalg.norm(decoder_np, axis=0) + 1e-8)\n",
    "\n",
    "    total_angles = 0.0\n",
    "    for eig_i in range(gt_eigvectors.shape[1]):\n",
    "        eigvector = norm_gt_eigvectors[:, eig_i]\n",
    "        total_angles += 1. - np.max(np.abs(norm_decoder.T @ eigvector)) ** 2\n",
    "\n",
    "    return total_angles / float(model.hidden_dim)\n",
    "\n",
    "\n",
    "def metric_subspace(model, gt_eigvectors, gt_eigs):\n",
    "    decoder_weight = get_weight_tensor_from_seq(model.decoder)\n",
    "    decoder_np = decoder_weight.detach().cpu().numpy()\n",
    "\n",
    "    # k - tr(UU^T WW^T), where W is left singular vector matrix of decoder\n",
    "    u, s, vh = np.linalg.svd(decoder_np, full_matrices=False)\n",
    "    return 1 - np.trace(gt_eigvectors @ gt_eigvectors.T @ u @ u.T) / float(model.hidden_dim)\n",
    "\n",
    "\n",
    "def metric_loss(model, data_loader):\n",
    "    \"\"\"\n",
    "    Measures the full batch loss\n",
    "    :param model: a linear (variational) AE model\n",
    "    :param data_loader: full batch data loader. Should be different from the training data loader, if in minibatch mode\n",
    "    \"\"\"\n",
    "    loss = None\n",
    "    for x in data_loader:\n",
    "        loss = model(x.to(device)).item()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def metric_recon_loss(model, data_loader):\n",
    "    recon_loss = None\n",
    "    for x in data_loader:\n",
    "        recon_loss = model.get_reconstruction_loss(x.to(device)).item()\n",
    "    return recon_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea8f6d7",
   "metadata": {},
   "source": [
    "### TRAING A MODEL (TESTING CONVEX CLUSTERING) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b18958dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GET DATA ####\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed=1234\n",
    "# set random seed\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "input_dim = 100\n",
    "hidden_dim = 5\n",
    "\n",
    "n_data = 50\n",
    "batch_size = n_data\n",
    "\n",
    "max_sv = float(input_dim) * 0.1\n",
    "min_sv = 1.0\n",
    "sigma = 0.5\n",
    "\n",
    "gt_data = DataGeneratorPCA(input_dim, hidden_dim, min_sv=min_sv, max_sv=max_sv, total=n_data)\n",
    "data = DataGeneratorPCA(input_dim, hidden_dim, load_data=gt_data.x_sample)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0da72f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'rotation', 'model_type': 'rotation', 'model_class': <class '__main__.LinearAE'>, 'extra_model_args': {'weight_reg_type': 'convex_cluster', 'gauss_coef': 1.0, 'neighbors': None}, 'input_dim': 100, 'hidden_dim': 5, 'init_scale': 0.0001, 'optim_class': <class 'torch.optim.sgd.SGD'>, 'extra_optim_args': {'momentum': 0.9, 'nesterov': True}, 'lr': 0.0001, 'train_itr': 1000, 'seed': 1234} \n",
      "\n",
      "LinearAE(\n",
      "  (encoder): Linear(in_features=100, out_features=5, bias=False)\n",
      "  (decoder): Linear(in_features=5, out_features=100, bias=False)\n",
      ") \n",
      "\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0\n",
      ")\n",
      "Transpose: 2.0780660634045487e-06 \n",
      "\n",
      "Distance to axis-aligned solution: 0.9531327848446475 \n",
      "\n",
      "Distance to optimal subspace): 0.9347729325294495 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Define the model ####\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#### DEFINE MODEL #####\n",
    "model_dict = dict(\n",
    "    model_name='rotation',\n",
    "    model_type='rotation',\n",
    "    model_class=LinearAE,\n",
    "    extra_model_args = {'weight_reg_type':'convex_cluster', 'gauss_coef':1.0, 'neighbors':None},\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    init_scale=0.0001,\n",
    "    optim_class=torch.optim.SGD,\n",
    "    extra_optim_args={'momentum': 0.9, 'nesterov': True},\n",
    "    lr=0.0001,\n",
    "    train_itr=1000,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "\n",
    "# model config contains the model \n",
    "model_config = ModelConfig(\n",
    "        model_name=model_dict['model_name'],\n",
    "        model_type=model_dict['model_type'],\n",
    "        model_class=model_dict['model_class'],\n",
    "        input_dim=model_dict['input_dim'], \n",
    "        hidden_dim=model_dict['hidden_dim'],\n",
    "        init_scale=model_dict['init_scale'],\n",
    "        extra_model_args=model_dict['extra_model_args'],\n",
    "        optim_class=model_dict['optim_class'],\n",
    "        lr=model_dict['lr'],\n",
    "        extra_optim_args=model_dict['extra_optim_args']\n",
    "    )\n",
    "\n",
    "print(model_dict,'\\n')\n",
    "print(model_config.get_model(),'\\n')\n",
    "print(model_config.get_optimizer())\n",
    "\n",
    "print('Transpose:', metric_transpose_theorem(model_config.get_model()),'\\n') # how close encoder and decoder.T are \n",
    "print('Distance to axis-aligned solution:', metric_alignment(model_config.get_model(), data.eigvectors),'\\n') # alignment of decoder columns to ground truth eigenvectors\n",
    "print('Distance to optimal subspace):', metric_subspace(model_config.get_model(), data.eigvectors, data.eigs),'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "129acd35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'rotation', 'model_type': 'rotation', 'model_class': <class '__main__.LinearAE'>, 'extra_model_args': {'weight_reg_type': None}, 'input_dim': 100, 'hidden_dim': 5, 'init_scale': 0.0001, 'optim_class': <class 'torch.optim.sgd.SGD'>, 'extra_optim_args': {'momentum': 0.9, 'nesterov': True}, 'lr': 0.0001, 'train_itr': 1000, 'seed': 1234} \n",
      "\n",
      "LinearAE(\n",
      "  (encoder): Linear(in_features=100, out_features=5, bias=False)\n",
      "  (decoder): Linear(in_features=5, out_features=100, bias=False)\n",
      ") \n",
      "\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0\n",
      ")\n",
      "Transpose: 2.064951513602864e-06 \n",
      "\n",
      "Distance to axis-aligned solution: 0.9740111924670842 \n",
      "\n",
      "Distance to optimal subspace): 0.9572605818510056 \n",
      "\n",
      "Reconstrution Loss: 555.1112670898438 \n",
      "\n",
      "Loss: 555.1112670898438 \n",
      "\n",
      "Transpose: 2.064951513602864e-06 \n",
      "\n",
      "Distance to axis-aligned solution: 0.9740111924670842 \n",
      "\n",
      "Distance to optimal subspace): 0.9572605818510056 \n",
      "\n",
      "Iteration = 1, Losses: rotation = 555.1112670898438 \n",
      "Iteration = 10, Losses: rotation = 555.1112060546875 \n",
      "Iteration = 20, Losses: rotation = 555.1111450195312 \n",
      "Iteration = 30, Losses: rotation = 555.111083984375 \n",
      "Iteration = 40, Losses: rotation = 555.1109008789062 \n",
      "Iteration = 50, Losses: rotation = 555.1104736328125 \n",
      "Iteration = 60, Losses: rotation = 555.1093139648438 \n",
      "Iteration = 70, Losses: rotation = 555.1065063476562 \n",
      "Iteration = 80, Losses: rotation = 555.0995483398438 \n",
      "Iteration = 90, Losses: rotation = 555.0814208984375 \n",
      "Iteration = 100, Losses: rotation = 555.0347290039062 \n",
      "Iteration = 110, Losses: rotation = 554.9129638671875 \n",
      "Iteration = 120, Losses: rotation = 554.5938720703125 \n",
      "Iteration = 130, Losses: rotation = 553.7576904296875 \n",
      "Iteration = 140, Losses: rotation = 551.5922241210938 \n",
      "Iteration = 150, Losses: rotation = 546.2120971679688 \n",
      "Iteration = 160, Losses: rotation = 534.3041381835938 \n",
      "Iteration = 170, Losses: rotation = 514.2384643554688 \n",
      "Iteration = 180, Losses: rotation = 492.7723693847656 \n",
      "Iteration = 190, Losses: rotation = 474.40460205078125 \n",
      "Iteration = 200, Losses: rotation = 457.348876953125 \n",
      "Iteration = 210, Losses: rotation = 443.9526062011719 \n",
      "Iteration = 220, Losses: rotation = 432.6116027832031 \n",
      "Iteration = 230, Losses: rotation = 418.8331604003906 \n",
      "Iteration = 240, Losses: rotation = 407.5255432128906 \n",
      "Iteration = 250, Losses: rotation = 403.5531311035156 \n",
      "Iteration = 260, Losses: rotation = 403.1991882324219 \n",
      "Iteration = 270, Losses: rotation = 403.090087890625 \n",
      "Iteration = 280, Losses: rotation = 402.953125 \n",
      "Iteration = 290, Losses: rotation = 402.8879699707031 \n",
      "Iteration = 300, Losses: rotation = 402.8525085449219 \n",
      "Iteration = 310, Losses: rotation = 402.82391357421875 \n",
      "Iteration = 320, Losses: rotation = 402.79925537109375 \n",
      "Iteration = 330, Losses: rotation = 402.7779541015625 \n",
      "Iteration = 340, Losses: rotation = 402.75921630859375 \n",
      "Iteration = 350, Losses: rotation = 402.74261474609375 \n",
      "Iteration = 360, Losses: rotation = 402.72772216796875 \n",
      "Iteration = 370, Losses: rotation = 402.7143249511719 \n",
      "Iteration = 380, Losses: rotation = 402.7022705078125 \n",
      "Iteration = 390, Losses: rotation = 402.6912536621094 \n",
      "Iteration = 400, Losses: rotation = 402.68121337890625 \n",
      "Iteration = 410, Losses: rotation = 402.6720275878906 \n",
      "Iteration = 420, Losses: rotation = 402.6635437011719 \n",
      "Iteration = 430, Losses: rotation = 402.6557312011719 \n",
      "Iteration = 440, Losses: rotation = 402.6484375 \n",
      "Iteration = 450, Losses: rotation = 402.6416320800781 \n",
      "Iteration = 460, Losses: rotation = 402.63531494140625 \n",
      "Iteration = 470, Losses: rotation = 402.6293029785156 \n",
      "Iteration = 480, Losses: rotation = 402.6236572265625 \n",
      "Iteration = 490, Losses: rotation = 402.6182861328125 \n",
      "Iteration = 500, Losses: rotation = 402.6131896972656 \n",
      "Iteration = 510, Losses: rotation = 402.6082763671875 \n",
      "Iteration = 520, Losses: rotation = 402.6036682128906 \n",
      "Iteration = 530, Losses: rotation = 402.5991516113281 \n",
      "Iteration = 540, Losses: rotation = 402.5948486328125 \n",
      "Iteration = 550, Losses: rotation = 402.5906677246094 \n",
      "Iteration = 560, Losses: rotation = 402.5865478515625 \n",
      "Iteration = 570, Losses: rotation = 402.5826110839844 \n",
      "Iteration = 580, Losses: rotation = 402.5787353515625 \n",
      "Iteration = 590, Losses: rotation = 402.574951171875 \n",
      "Iteration = 600, Losses: rotation = 402.5711975097656 \n",
      "Iteration = 610, Losses: rotation = 402.5675354003906 \n",
      "Iteration = 620, Losses: rotation = 402.5638732910156 \n",
      "Iteration = 630, Losses: rotation = 402.5602722167969 \n",
      "Iteration = 640, Losses: rotation = 402.5566711425781 \n",
      "Iteration = 650, Losses: rotation = 402.55303955078125 \n",
      "Iteration = 660, Losses: rotation = 402.5494384765625 \n",
      "Iteration = 670, Losses: rotation = 402.5458679199219 \n",
      "Iteration = 680, Losses: rotation = 402.54217529296875 \n",
      "Iteration = 690, Losses: rotation = 402.53863525390625 \n",
      "Iteration = 700, Losses: rotation = 402.5348815917969 \n",
      "Iteration = 710, Losses: rotation = 402.5311584472656 \n",
      "Iteration = 720, Losses: rotation = 402.52734375 \n",
      "Iteration = 730, Losses: rotation = 402.5235290527344 \n",
      "Iteration = 740, Losses: rotation = 402.5196228027344 \n",
      "Iteration = 750, Losses: rotation = 402.515625 \n",
      "Iteration = 760, Losses: rotation = 402.51153564453125 \n",
      "Iteration = 770, Losses: rotation = 402.50738525390625 \n",
      "Iteration = 780, Losses: rotation = 402.5030822753906 \n",
      "Iteration = 790, Losses: rotation = 402.49871826171875 \n",
      "Iteration = 800, Losses: rotation = 402.4942321777344 \n",
      "Iteration = 810, Losses: rotation = 402.4896240234375 \n",
      "Iteration = 820, Losses: rotation = 402.4848327636719 \n",
      "Iteration = 830, Losses: rotation = 402.4799499511719 \n",
      "Iteration = 840, Losses: rotation = 402.4749755859375 \n",
      "Iteration = 850, Losses: rotation = 402.4697265625 \n",
      "Iteration = 860, Losses: rotation = 402.4643859863281 \n",
      "Iteration = 870, Losses: rotation = 402.4588317871094 \n",
      "Iteration = 880, Losses: rotation = 402.453125 \n",
      "Iteration = 890, Losses: rotation = 402.4471740722656 \n",
      "Iteration = 900, Losses: rotation = 402.4410400390625 \n",
      "Iteration = 910, Losses: rotation = 402.4347229003906 \n",
      "Iteration = 920, Losses: rotation = 402.42816162109375 \n",
      "Iteration = 930, Losses: rotation = 402.4214172363281 \n",
      "Iteration = 940, Losses: rotation = 402.41436767578125 \n",
      "Iteration = 950, Losses: rotation = 402.4071350097656 \n",
      "Iteration = 960, Losses: rotation = 402.39959716796875 \n",
      "Iteration = 970, Losses: rotation = 402.391845703125 \n",
      "Iteration = 980, Losses: rotation = 402.3838195800781 \n",
      "Iteration = 990, Losses: rotation = 402.3754577636719 \n",
      "Iteration = 1000, Losses: rotation = 402.36688232421875 \n",
      "Iteration = 1010, Losses: rotation = 402.3578796386719 \n",
      "Iteration = 1020, Losses: rotation = 402.3486633300781 \n",
      "Iteration = 1030, Losses: rotation = 402.33905029296875 \n",
      "Iteration = 1040, Losses: rotation = 402.3291320800781 \n",
      "Iteration = 1050, Losses: rotation = 402.3189392089844 \n",
      "Iteration = 1060, Losses: rotation = 402.308349609375 \n",
      "Iteration = 1070, Losses: rotation = 402.29742431640625 \n",
      "Iteration = 1080, Losses: rotation = 402.2861328125 \n",
      "Iteration = 1090, Losses: rotation = 402.2743835449219 \n",
      "Iteration = 1100, Losses: rotation = 402.26226806640625 \n",
      "Iteration = 1110, Losses: rotation = 402.2498779296875 \n",
      "Iteration = 1120, Losses: rotation = 402.2369384765625 \n",
      "Iteration = 1130, Losses: rotation = 402.2236633300781 \n",
      "Iteration = 1140, Losses: rotation = 402.2099914550781 \n",
      "Iteration = 1150, Losses: rotation = 402.1958923339844 \n",
      "Iteration = 1160, Losses: rotation = 402.1813659667969 \n",
      "Iteration = 1170, Losses: rotation = 402.1664123535156 \n",
      "Iteration = 1180, Losses: rotation = 402.1510009765625 \n",
      "Iteration = 1190, Losses: rotation = 402.13519287109375 \n",
      "Iteration = 1200, Losses: rotation = 402.11883544921875 \n",
      "Iteration = 1210, Losses: rotation = 402.10223388671875 \n",
      "Iteration = 1220, Losses: rotation = 402.0849914550781 \n",
      "Iteration = 1230, Losses: rotation = 402.0674133300781 \n",
      "Iteration = 1240, Losses: rotation = 402.0493469238281 \n",
      "Iteration = 1250, Losses: rotation = 402.03082275390625 \n",
      "Iteration = 1260, Losses: rotation = 402.0118713378906 \n",
      "Iteration = 1270, Losses: rotation = 401.9925537109375 \n",
      "Iteration = 1280, Losses: rotation = 401.9726867675781 \n",
      "Iteration = 1290, Losses: rotation = 401.9525146484375 \n",
      "Iteration = 1300, Losses: rotation = 401.9317932128906 \n",
      "Iteration = 1310, Losses: rotation = 401.91082763671875 \n",
      "Iteration = 1320, Losses: rotation = 401.8892822265625 \n",
      "Iteration = 1330, Losses: rotation = 401.8674621582031 \n",
      "Iteration = 1340, Losses: rotation = 401.8452453613281 \n",
      "Iteration = 1350, Losses: rotation = 401.8226318359375 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 1360, Losses: rotation = 401.7996826171875 \n",
      "Iteration = 1370, Losses: rotation = 401.7763977050781 \n",
      "Iteration = 1380, Losses: rotation = 401.7528076171875 \n",
      "Iteration = 1390, Losses: rotation = 401.7289123535156 \n",
      "Iteration = 1400, Losses: rotation = 401.7047119140625 \n",
      "Iteration = 1410, Losses: rotation = 401.6802978515625 \n",
      "Iteration = 1420, Losses: rotation = 401.6556396484375 \n",
      "Iteration = 1430, Losses: rotation = 401.6307067871094 \n",
      "Iteration = 1440, Losses: rotation = 401.60565185546875 \n",
      "Iteration = 1450, Losses: rotation = 401.58038330078125 \n",
      "Iteration = 1460, Losses: rotation = 401.55499267578125 \n",
      "Iteration = 1470, Losses: rotation = 401.5294494628906 \n",
      "Iteration = 1480, Losses: rotation = 401.5038146972656 \n",
      "Iteration = 1490, Losses: rotation = 401.4781494140625 \n",
      "Iteration = 1500, Losses: rotation = 401.4524230957031 \n",
      "Iteration = 1510, Losses: rotation = 401.4266357421875 \n",
      "Iteration = 1520, Losses: rotation = 401.40093994140625 \n",
      "Iteration = 1530, Losses: rotation = 401.375244140625 \n",
      "Iteration = 1540, Losses: rotation = 401.349609375 \n",
      "Iteration = 1550, Losses: rotation = 401.32403564453125 \n",
      "Iteration = 1560, Losses: rotation = 401.29864501953125 \n",
      "Iteration = 1570, Losses: rotation = 401.2733154296875 \n",
      "Iteration = 1580, Losses: rotation = 401.2481689453125 \n",
      "Iteration = 1590, Losses: rotation = 401.22320556640625 \n",
      "Iteration = 1600, Losses: rotation = 401.19842529296875 \n",
      "Iteration = 1610, Losses: rotation = 401.1739501953125 \n",
      "Iteration = 1620, Losses: rotation = 401.14971923828125 \n",
      "Iteration = 1630, Losses: rotation = 401.125732421875 \n",
      "Iteration = 1640, Losses: rotation = 401.1020202636719 \n",
      "Iteration = 1650, Losses: rotation = 401.07867431640625 \n",
      "Iteration = 1660, Losses: rotation = 401.0556335449219 \n",
      "Iteration = 1670, Losses: rotation = 401.0329284667969 \n",
      "Iteration = 1680, Losses: rotation = 401.0105895996094 \n",
      "Iteration = 1690, Losses: rotation = 400.9886474609375 \n",
      "Iteration = 1700, Losses: rotation = 400.9670715332031 \n",
      "Iteration = 1710, Losses: rotation = 400.9458923339844 \n",
      "Iteration = 1720, Losses: rotation = 400.9251708984375 \n",
      "Iteration = 1730, Losses: rotation = 400.9047546386719 \n",
      "Iteration = 1740, Losses: rotation = 400.8848571777344 \n",
      "Iteration = 1750, Losses: rotation = 400.8653869628906 \n",
      "Iteration = 1760, Losses: rotation = 400.8463134765625 \n",
      "Iteration = 1770, Losses: rotation = 400.82769775390625 \n",
      "Iteration = 1780, Losses: rotation = 400.8095397949219 \n",
      "Iteration = 1790, Losses: rotation = 400.79180908203125 \n",
      "Iteration = 1800, Losses: rotation = 400.7745361328125 \n",
      "Iteration = 1810, Losses: rotation = 400.7577209472656 \n",
      "Iteration = 1820, Losses: rotation = 400.7413635253906 \n",
      "Iteration = 1830, Losses: rotation = 400.7254333496094 \n",
      "Iteration = 1840, Losses: rotation = 400.7099609375 \n",
      "Iteration = 1850, Losses: rotation = 400.6949157714844 \n",
      "Iteration = 1860, Losses: rotation = 400.6802673339844 \n",
      "Iteration = 1870, Losses: rotation = 400.6661071777344 \n",
      "Iteration = 1880, Losses: rotation = 400.6523742675781 \n",
      "Iteration = 1890, Losses: rotation = 400.6390380859375 \n",
      "Iteration = 1900, Losses: rotation = 400.62615966796875 \n",
      "Iteration = 1910, Losses: rotation = 400.6136474609375 \n",
      "Iteration = 1920, Losses: rotation = 400.6015319824219 \n",
      "Iteration = 1930, Losses: rotation = 400.58984375 \n",
      "Iteration = 1940, Losses: rotation = 400.5785217285156 \n",
      "Iteration = 1950, Losses: rotation = 400.56756591796875 \n",
      "Iteration = 1960, Losses: rotation = 400.5570068359375 \n",
      "Iteration = 1970, Losses: rotation = 400.5467529296875 \n",
      "Iteration = 1980, Losses: rotation = 400.5369567871094 \n",
      "Iteration = 1990, Losses: rotation = 400.5274353027344 \n",
      "Iteration = 2000, Losses: rotation = 400.5182800292969 \n",
      "Iteration = 2010, Losses: rotation = 400.50946044921875 \n",
      "Iteration = 2020, Losses: rotation = 400.5009460449219 \n",
      "Iteration = 2030, Losses: rotation = 400.4927062988281 \n",
      "Iteration = 2040, Losses: rotation = 400.48480224609375 \n",
      "Iteration = 2050, Losses: rotation = 400.4771423339844 \n",
      "Iteration = 2060, Losses: rotation = 400.4698791503906 \n",
      "Iteration = 2070, Losses: rotation = 400.4627685546875 \n",
      "Iteration = 2080, Losses: rotation = 400.4560241699219 \n",
      "Iteration = 2090, Losses: rotation = 400.4494934082031 \n",
      "Iteration = 2100, Losses: rotation = 400.44317626953125 \n",
      "Iteration = 2110, Losses: rotation = 400.4371337890625 \n",
      "Iteration = 2120, Losses: rotation = 400.4313659667969 \n",
      "Iteration = 2130, Losses: rotation = 400.42578125 \n",
      "Iteration = 2140, Losses: rotation = 400.42047119140625 \n",
      "Iteration = 2150, Losses: rotation = 400.4153137207031 \n",
      "Iteration = 2160, Losses: rotation = 400.41033935546875 \n",
      "Iteration = 2170, Losses: rotation = 400.4056396484375 \n",
      "Iteration = 2180, Losses: rotation = 400.4010925292969 \n",
      "Iteration = 2190, Losses: rotation = 400.396728515625 \n",
      "Iteration = 2200, Losses: rotation = 400.3924865722656 \n",
      "Iteration = 2210, Losses: rotation = 400.38848876953125 \n",
      "Iteration = 2220, Losses: rotation = 400.3846130371094 \n",
      "Iteration = 2230, Losses: rotation = 400.3809509277344 \n",
      "Iteration = 2240, Losses: rotation = 400.37738037109375 \n",
      "Iteration = 2250, Losses: rotation = 400.3739929199219 \n",
      "Iteration = 2260, Losses: rotation = 400.3706970214844 \n",
      "Iteration = 2270, Losses: rotation = 400.3675842285156 \n",
      "Iteration = 2280, Losses: rotation = 400.3646240234375 \n",
      "Iteration = 2290, Losses: rotation = 400.3617248535156 \n",
      "Iteration = 2300, Losses: rotation = 400.3589782714844 \n",
      "Iteration = 2310, Losses: rotation = 400.3563232421875 \n",
      "Iteration = 2320, Losses: rotation = 400.35382080078125 \n",
      "Iteration = 2330, Losses: rotation = 400.35137939453125 \n",
      "Iteration = 2340, Losses: rotation = 400.34906005859375 \n",
      "Iteration = 2350, Losses: rotation = 400.3468322753906 \n",
      "Iteration = 2360, Losses: rotation = 400.3446960449219 \n",
      "Iteration = 2370, Losses: rotation = 400.3426513671875 \n",
      "Iteration = 2380, Losses: rotation = 400.3406982421875 \n",
      "Iteration = 2390, Losses: rotation = 400.3388366699219 \n",
      "Iteration = 2400, Losses: rotation = 400.3370666503906 \n",
      "Iteration = 2410, Losses: rotation = 400.3353576660156 \n",
      "Iteration = 2420, Losses: rotation = 400.333740234375 \n",
      "Iteration = 2430, Losses: rotation = 400.3321838378906 \n",
      "Iteration = 2440, Losses: rotation = 400.33062744140625 \n",
      "Iteration = 2450, Losses: rotation = 400.3292236328125 \n",
      "Iteration = 2460, Losses: rotation = 400.3278503417969 \n",
      "Iteration = 2470, Losses: rotation = 400.3265380859375 \n",
      "Iteration = 2480, Losses: rotation = 400.3252258300781 \n",
      "Iteration = 2490, Losses: rotation = 400.3240661621094 \n",
      "Iteration = 2500, Losses: rotation = 400.3228759765625 \n",
      "Iteration = 2510, Losses: rotation = 400.3218078613281 \n",
      "Iteration = 2520, Losses: rotation = 400.32073974609375 \n",
      "Iteration = 2530, Losses: rotation = 400.31976318359375 \n",
      "Iteration = 2540, Losses: rotation = 400.31878662109375 \n",
      "Iteration = 2550, Losses: rotation = 400.3178405761719 \n",
      "Iteration = 2560, Losses: rotation = 400.31695556640625 \n",
      "Iteration = 2570, Losses: rotation = 400.31610107421875 \n",
      "Iteration = 2580, Losses: rotation = 400.3153076171875 \n",
      "Iteration = 2590, Losses: rotation = 400.3145446777344 \n",
      "Iteration = 2600, Losses: rotation = 400.3137512207031 \n",
      "Iteration = 2610, Losses: rotation = 400.3130798339844 \n",
      "Iteration = 2620, Losses: rotation = 400.3124084472656 \n",
      "Iteration = 2630, Losses: rotation = 400.311767578125 \n",
      "Iteration = 2640, Losses: rotation = 400.31109619140625 \n",
      "Iteration = 2650, Losses: rotation = 400.310546875 \n",
      "Iteration = 2660, Losses: rotation = 400.30999755859375 \n",
      "Iteration = 2670, Losses: rotation = 400.3094482421875 \n",
      "Iteration = 2680, Losses: rotation = 400.3089599609375 \n",
      "Iteration = 2690, Losses: rotation = 400.3084411621094 \n",
      "Iteration = 2700, Losses: rotation = 400.3079833984375 \n",
      "Iteration = 2710, Losses: rotation = 400.3074951171875 \n",
      "Iteration = 2720, Losses: rotation = 400.30706787109375 \n",
      "Iteration = 2730, Losses: rotation = 400.3066711425781 \n",
      "Iteration = 2740, Losses: rotation = 400.3062744140625 \n",
      "Iteration = 2750, Losses: rotation = 400.30584716796875 \n",
      "Iteration = 2760, Losses: rotation = 400.3055114746094 \n",
      "Iteration = 2770, Losses: rotation = 400.3051452636719 \n",
      "Iteration = 2780, Losses: rotation = 400.3048400878906 \n",
      "Iteration = 2790, Losses: rotation = 400.3045349121094 \n",
      "Iteration = 2800, Losses: rotation = 400.30426025390625 \n",
      "Iteration = 2810, Losses: rotation = 400.303955078125 \n",
      "Iteration = 2820, Losses: rotation = 400.3036804199219 \n",
      "Iteration = 2830, Losses: rotation = 400.30340576171875 \n",
      "Iteration = 2840, Losses: rotation = 400.30316162109375 \n",
      "Iteration = 2850, Losses: rotation = 400.30291748046875 \n",
      "Iteration = 2860, Losses: rotation = 400.3026428222656 \n",
      "Iteration = 2870, Losses: rotation = 400.30242919921875 \n",
      "Iteration = 2880, Losses: rotation = 400.3022155761719 \n",
      "Iteration = 2890, Losses: rotation = 400.30206298828125 \n",
      "Iteration = 2900, Losses: rotation = 400.3018798828125 \n",
      "Iteration = 2910, Losses: rotation = 400.3016357421875 \n",
      "Iteration = 2920, Losses: rotation = 400.3014831542969 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 2930, Losses: rotation = 400.3013000488281 \n",
      "Iteration = 2940, Losses: rotation = 400.3011779785156 \n",
      "Iteration = 2950, Losses: rotation = 400.301025390625 \n",
      "Iteration = 2960, Losses: rotation = 400.3009033203125 \n",
      "Iteration = 2970, Losses: rotation = 400.3006896972656 \n",
      "Iteration = 2980, Losses: rotation = 400.30059814453125 \n",
      "Iteration = 2990, Losses: rotation = 400.3004150390625 \n",
      "Iteration = 3000, Losses: rotation = 400.3003234863281 \n",
      "Reconstrution Loss: 400.3003234863281 \n",
      "\n",
      "Loss: 400.3003234863281 \n",
      "\n",
      "Transpose: 2.2936279492569157e-06 \n",
      "\n",
      "Distance to axis-aligned solution: 0.19753874445063957 \n",
      "\n",
      "Distance to optimal subspace): 0.00022840499877929688 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Define the model ####\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#### DEFINE MODEL #####\n",
    "model_dict = dict(\n",
    "    model_name='rotation',\n",
    "    model_type='rotation',\n",
    "    model_class=LinearAE,\n",
    "    extra_model_args = {'weight_reg_type':None},\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    init_scale=0.0001,\n",
    "    optim_class=torch.optim.SGD,\n",
    "    extra_optim_args={'momentum': 0.9, 'nesterov': True},\n",
    "    lr=0.0001,\n",
    "    train_itr=1000,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "\n",
    "# model config contains the model \n",
    "model_config = ModelConfig(\n",
    "        model_name=model_dict['model_name'],\n",
    "        model_type=model_dict['model_type'],\n",
    "        model_class=model_dict['model_class'],\n",
    "        input_dim=model_dict['input_dim'], \n",
    "        hidden_dim=model_dict['hidden_dim'],\n",
    "        init_scale=model_dict['init_scale'],\n",
    "        extra_model_args=model_dict['extra_model_args'],\n",
    "        optim_class=model_dict['optim_class'],\n",
    "        lr=model_dict['lr'],\n",
    "        extra_optim_args=model_dict['extra_optim_args']\n",
    "    )\n",
    "\n",
    "print(model_dict,'\\n')\n",
    "print(model_config.get_model(),'\\n')\n",
    "print(model_config.get_optimizer())\n",
    "\n",
    "print('Transpose:', metric_transpose_theorem(model_config.get_model()),'\\n') # how close encoder and decoder.T are \n",
    "print('Distance to axis-aligned solution:', metric_alignment(model_config.get_model(), data.eigvectors),'\\n') # alignment of decoder columns to ground truth eigenvectors\n",
    "print('Distance to optimal subspace):', metric_subspace(model_config.get_model(), data.eigvectors, data.eigs),'\\n')\n",
    "\n",
    "\n",
    "modelIn = model_config.get_model()\n",
    "print('Reconstrution Loss:', metric_recon_loss(modelIn, loader),'\\n') # full batch loss\n",
    "print('Loss:', metric_loss(modelIn, loader),'\\n')\n",
    "print('Transpose:', metric_transpose_theorem(modelIn),'\\n') # how close encoder and decoder.T are \n",
    "print('Distance to axis-aligned solution:', metric_alignment(modelIn, data.eigvectors),'\\n') # alignment of decoder columns to ground truth eigenvectors\n",
    "print('Distance to optimal subspace):', metric_subspace(modelIn, data.eigvectors, data.eigs),'\\n')\n",
    "\n",
    "trained_model = train_models(data_loader=loader, train_itr=3000, metrics_dict=None, model_configs=model_config)\n",
    "# trained_model = train_models(data_loader=loader, train_itr=model_dict['train_itr'], metrics_dict=None, model_configs=model_config)\n",
    "\n",
    "modelIn = model_config.get_model()\n",
    "print('Reconstrution Loss:', metric_recon_loss(modelIn, loader),'\\n') # full batch loss\n",
    "print('Loss:', metric_loss(modelIn, loader),'\\n')\n",
    "print('Transpose:', metric_transpose_theorem(modelIn),'\\n') # how close encoder and decoder.T are \n",
    "print('Distance to axis-aligned solution:', metric_alignment(modelIn, data.eigvectors),'\\n') # alignment of decoder columns to ground truth eigenvectors\n",
    "print('Distance to optimal subspace):', metric_subspace(modelIn, data.eigvectors, data.eigs),'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ed573617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'rotation', 'model_type': 'rotation', 'model_class': <class '__main__.LinearAE'>, 'extra_model_args': {'weight_reg_type': 'convex_cluster', 'gauss_coef': 1.0, 'neighbors': None}, 'input_dim': 100, 'hidden_dim': 5, 'init_scale': 0.0001, 'optim_class': <class 'torch.optim.sgd.SGD'>, 'extra_optim_args': {'momentum': 0.9, 'nesterov': True}, 'lr': 0.0001, 'train_itr': 1000, 'seed': 1234} \n",
      "\n",
      "LinearAE(\n",
      "  (encoder): Linear(in_features=100, out_features=5, bias=False)\n",
      "  (decoder): Linear(in_features=5, out_features=100, bias=False)\n",
      ") \n",
      "\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0\n",
      ")\n",
      "Transpose: 2.0612884327420034e-06 \n",
      "\n",
      "Distance to axis-aligned solution: 0.9811180198675457 \n",
      "\n",
      "Distance to optimal subspace): 0.9638129651546479 \n",
      "\n",
      "Reconstrution Loss: 555.1112670898438 \n",
      "\n",
      "Getting convex clustering weights.\n",
      "torch.Size([1225])\n",
      "Loss: 555.1112670898438 \n",
      "\n",
      "Transpose: 2.0612884327420034e-06 \n",
      "\n",
      "Distance to axis-aligned solution: 0.9811180198675457 \n",
      "\n",
      "Distance to optimal subspace): 0.9638129651546479 \n",
      "\n",
      "Iteration = 1, Losses: rotation = 555.1662380793757 \n",
      "Iteration = 10, Losses: rotation = 555.1680987075441 \n",
      "Iteration = 20, Losses: rotation = 555.1806302837283 \n",
      "Iteration = 30, Losses: rotation = 555.2157119306006 \n",
      "Iteration = 40, Losses: rotation = 555.2975759737442 \n",
      "Iteration = 50, Losses: rotation = 555.4899818358775 \n",
      "Iteration = 60, Losses: rotation = 555.9582088899128 \n",
      "Iteration = 70, Losses: rotation = 557.1319017327377 \n",
      "Iteration = 80, Losses: rotation = 560.1387098311462 \n",
      "Iteration = 90, Losses: rotation = 567.965687939866 \n",
      "Iteration = 100, Losses: rotation = 588.5954381161857 \n",
      "Iteration = 110, Losses: rotation = 643.4860595919192 \n",
      "Iteration = 120, Losses: rotation = 790.5287008833943 \n",
      "Iteration = 130, Losses: rotation = 1185.7836541748984 \n",
      "Iteration = 140, Losses: rotation = 2245.071451406957 \n",
      "Iteration = 150, Losses: rotation = 5032.261020618665 \n",
      "Iteration = 160, Losses: rotation = 11956.560635621374 \n",
      "Iteration = 170, Losses: rotation = 26763.18838460711 \n",
      "Iteration = 180, Losses: rotation = 49686.24345004222 \n",
      "Iteration = 190, Losses: rotation = 71645.85079544786 \n",
      "Iteration = 200, Losses: rotation = 87852.59724193631 \n",
      "Iteration = 210, Losses: rotation = 101376.27079145797 \n",
      "Iteration = 220, Losses: rotation = 111727.02252485574 \n",
      "Iteration = 230, Losses: rotation = 117833.04422647883 \n",
      "Iteration = 240, Losses: rotation = 120289.42235483005 \n",
      "Iteration = 250, Losses: rotation = 120496.28140246311 \n",
      "Iteration = 260, Losses: rotation = 121224.69230010195 \n",
      "Iteration = 270, Losses: rotation = 124013.38414453343 \n",
      "Iteration = 280, Losses: rotation = 127679.95768400916 \n",
      "Iteration = 290, Losses: rotation = 130007.75012431576 \n",
      "Iteration = 300, Losses: rotation = 130458.5024365405 \n",
      "Iteration = 310, Losses: rotation = 130025.17993166417 \n",
      "Iteration = 320, Losses: rotation = 129578.3268300555 \n",
      "Iteration = 330, Losses: rotation = 129384.31629538994 \n",
      "Iteration = 340, Losses: rotation = 129384.68325725233 \n",
      "Iteration = 350, Losses: rotation = 129457.48270170421 \n",
      "Iteration = 360, Losses: rotation = 129524.79192017499 \n",
      "Iteration = 370, Losses: rotation = 129563.97966296691 \n",
      "Iteration = 380, Losses: rotation = 129582.51164996947 \n",
      "Iteration = 390, Losses: rotation = 129593.57800209384 \n",
      "Iteration = 400, Losses: rotation = 129605.17235806576 \n",
      "Iteration = 410, Losses: rotation = 129619.39158238622 \n",
      "Iteration = 420, Losses: rotation = 129635.44810729512 \n",
      "Iteration = 430, Losses: rotation = 129652.16249841462 \n",
      "Iteration = 440, Losses: rotation = 129668.96124277485 \n",
      "Iteration = 450, Losses: rotation = 129685.88006908994 \n",
      "Iteration = 460, Losses: rotation = 129703.2155859056 \n",
      "Iteration = 470, Losses: rotation = 129721.22769572254 \n",
      "Iteration = 480, Losses: rotation = 129740.08530132854 \n",
      "Iteration = 490, Losses: rotation = 129759.82250465803 \n",
      "Iteration = 500, Losses: rotation = 129780.41272665962 \n",
      "Iteration = 510, Losses: rotation = 129801.78147775699 \n",
      "Iteration = 520, Losses: rotation = 129823.84431165922 \n",
      "Iteration = 530, Losses: rotation = 129846.52332659235 \n",
      "Iteration = 540, Losses: rotation = 129869.72428909446 \n",
      "Iteration = 550, Losses: rotation = 129893.38962892049 \n",
      "Iteration = 560, Losses: rotation = 129917.42083549511 \n",
      "Iteration = 570, Losses: rotation = 129941.74871395266 \n",
      "Iteration = 580, Losses: rotation = 129966.3078939608 \n",
      "Iteration = 590, Losses: rotation = 129991.01970303118 \n",
      "Iteration = 600, Losses: rotation = 130015.82117757192 \n",
      "Iteration = 610, Losses: rotation = 130040.65490211904 \n",
      "Iteration = 620, Losses: rotation = 130065.45914961566 \n",
      "Iteration = 630, Losses: rotation = 130090.16407648684 \n",
      "Iteration = 640, Losses: rotation = 130114.73030170288 \n",
      "Iteration = 650, Losses: rotation = 130139.0888236629 \n",
      "Iteration = 660, Losses: rotation = 130163.2026406457 \n",
      "Iteration = 670, Losses: rotation = 130187.01373540869 \n",
      "Iteration = 680, Losses: rotation = 130210.48832174194 \n",
      "Iteration = 690, Losses: rotation = 130233.57192321385 \n",
      "Iteration = 700, Losses: rotation = 130256.22344331456 \n",
      "Iteration = 710, Losses: rotation = 130278.42197831097 \n",
      "Iteration = 720, Losses: rotation = 130300.13654666455 \n",
      "Iteration = 730, Losses: rotation = 130321.33326477745 \n",
      "Iteration = 740, Losses: rotation = 130342.00878598663 \n",
      "Iteration = 750, Losses: rotation = 130362.13456979208 \n",
      "Iteration = 760, Losses: rotation = 130381.70554731919 \n",
      "Iteration = 770, Losses: rotation = 130400.72797585829 \n",
      "Iteration = 780, Losses: rotation = 130419.19091085313 \n",
      "Iteration = 790, Losses: rotation = 130437.10346042331 \n",
      "Iteration = 800, Losses: rotation = 130454.4872494377 \n",
      "Iteration = 810, Losses: rotation = 130471.34154168455 \n",
      "Iteration = 820, Losses: rotation = 130487.6685859225 \n",
      "Iteration = 830, Losses: rotation = 130503.45650553465 \n",
      "Iteration = 840, Losses: rotation = 130518.71343587383 \n",
      "Iteration = 850, Losses: rotation = 130533.41585440302 \n",
      "Iteration = 860, Losses: rotation = 130547.56668114156 \n",
      "Iteration = 870, Losses: rotation = 130561.16219697063 \n",
      "Iteration = 880, Losses: rotation = 130574.20213646594 \n",
      "Iteration = 890, Losses: rotation = 130586.69008844759 \n",
      "Iteration = 900, Losses: rotation = 130598.63491322439 \n",
      "Iteration = 910, Losses: rotation = 130610.05252202084 \n",
      "Iteration = 920, Losses: rotation = 130620.95804309486 \n",
      "Iteration = 930, Losses: rotation = 130631.36047231086 \n",
      "Iteration = 940, Losses: rotation = 130641.2797792819 \n",
      "Iteration = 950, Losses: rotation = 130650.7238631961 \n",
      "Iteration = 960, Losses: rotation = 130659.7224900166 \n",
      "Iteration = 970, Losses: rotation = 130668.28100349069 \n",
      "Iteration = 980, Losses: rotation = 130676.42722546778 \n",
      "Iteration = 990, Losses: rotation = 130684.16569230157 \n",
      "Iteration = 1000, Losses: rotation = 130691.52264814888 \n",
      "Iteration = 1010, Losses: rotation = 130698.50981954549 \n",
      "Iteration = 1020, Losses: rotation = 130705.14089605522 \n",
      "Iteration = 1030, Losses: rotation = 130711.44683020416 \n",
      "Iteration = 1040, Losses: rotation = 130717.42480716026 \n",
      "Iteration = 1050, Losses: rotation = 130723.09851867543 \n",
      "Iteration = 1060, Losses: rotation = 130728.48299842153 \n",
      "Iteration = 1070, Losses: rotation = 130733.58526902975 \n",
      "Iteration = 1080, Losses: rotation = 130738.42777609582 \n",
      "Iteration = 1090, Losses: rotation = 130743.01833679789 \n",
      "Iteration = 1100, Losses: rotation = 130747.36369374974 \n",
      "Iteration = 1110, Losses: rotation = 130751.49262409739 \n",
      "Iteration = 1120, Losses: rotation = 130755.40109422841 \n",
      "Iteration = 1130, Losses: rotation = 130759.098859622 \n",
      "Iteration = 1140, Losses: rotation = 130762.6093642932 \n",
      "Iteration = 1150, Losses: rotation = 130765.93495807005 \n",
      "Iteration = 1160, Losses: rotation = 130769.08599332356 \n",
      "Iteration = 1170, Losses: rotation = 130772.06420573058 \n",
      "Iteration = 1180, Losses: rotation = 130774.88680300173 \n",
      "Iteration = 1190, Losses: rotation = 130777.5644646349 \n",
      "Iteration = 1200, Losses: rotation = 130780.09729501238 \n",
      "Iteration = 1210, Losses: rotation = 130782.4981949267 \n",
      "Iteration = 1220, Losses: rotation = 130784.76716562048 \n",
      "Iteration = 1230, Losses: rotation = 130786.91980016168 \n",
      "Iteration = 1240, Losses: rotation = 130788.95363810107 \n",
      "Iteration = 1250, Losses: rotation = 130790.87897220787 \n",
      "Iteration = 1260, Losses: rotation = 130792.6984297374 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 1270, Losses: rotation = 130794.42448369254 \n",
      "Iteration = 1280, Losses: rotation = 130796.05611676889 \n",
      "Iteration = 1290, Losses: rotation = 130797.59891847608 \n",
      "Iteration = 1300, Losses: rotation = 130799.06280713933 \n",
      "Iteration = 1310, Losses: rotation = 130800.44362436509 \n",
      "Iteration = 1320, Losses: rotation = 130801.74777797647 \n",
      "Iteration = 1330, Losses: rotation = 130802.9827922427 \n",
      "Iteration = 1340, Losses: rotation = 130804.1552740793 \n",
      "Iteration = 1350, Losses: rotation = 130805.25535717247 \n",
      "Iteration = 1360, Losses: rotation = 130806.30052248527 \n",
      "Iteration = 1370, Losses: rotation = 130807.2849150665 \n",
      "Iteration = 1380, Losses: rotation = 130808.2120794023 \n",
      "Iteration = 1390, Losses: rotation = 130809.0939304011 \n",
      "Iteration = 1400, Losses: rotation = 130809.92480465987 \n",
      "Iteration = 1410, Losses: rotation = 130810.70993593833 \n",
      "Iteration = 1420, Losses: rotation = 130811.44589218208 \n",
      "Iteration = 1430, Losses: rotation = 130812.1485749681 \n",
      "Iteration = 1440, Losses: rotation = 130812.80233036046 \n",
      "Iteration = 1450, Losses: rotation = 130813.42179471096 \n",
      "Iteration = 1460, Losses: rotation = 130814.00018074512 \n",
      "Iteration = 1470, Losses: rotation = 130814.5479389888 \n",
      "Iteration = 1480, Losses: rotation = 130815.06477540395 \n",
      "Iteration = 1490, Losses: rotation = 130815.55080673717 \n",
      "Iteration = 1500, Losses: rotation = 130816.00674422424 \n",
      "Iteration = 1510, Losses: rotation = 130816.43958989342 \n",
      "Iteration = 1520, Losses: rotation = 130816.84020073857 \n",
      "Iteration = 1530, Losses: rotation = 130817.20757179549 \n",
      "Iteration = 1540, Losses: rotation = 130817.56819001597 \n",
      "Iteration = 1550, Losses: rotation = 130817.90408492129 \n",
      "Iteration = 1560, Losses: rotation = 130818.21212411237 \n",
      "Iteration = 1570, Losses: rotation = 130818.4980935218 \n",
      "Iteration = 1580, Losses: rotation = 130818.76827425652 \n",
      "Iteration = 1590, Losses: rotation = 130819.01415457806 \n",
      "Iteration = 1600, Losses: rotation = 130819.24959129757 \n",
      "Iteration = 1610, Losses: rotation = 130819.46595159714 \n",
      "Iteration = 1620, Losses: rotation = 130819.67085963167 \n",
      "Iteration = 1630, Losses: rotation = 130819.8533342012 \n",
      "Iteration = 1640, Losses: rotation = 130820.0233342828 \n",
      "Iteration = 1650, Losses: rotation = 130820.18429536314 \n",
      "Iteration = 1660, Losses: rotation = 130820.33282164343 \n",
      "Iteration = 1670, Losses: rotation = 130820.46338296711 \n",
      "Iteration = 1680, Losses: rotation = 130820.59205399622 \n",
      "Iteration = 1690, Losses: rotation = 130820.70071955623 \n",
      "Iteration = 1700, Losses: rotation = 130820.80104186572 \n",
      "Iteration = 1710, Losses: rotation = 130820.89726726724 \n",
      "Iteration = 1720, Losses: rotation = 130820.97767750605 \n",
      "Iteration = 1730, Losses: rotation = 130821.05500790705 \n",
      "Iteration = 1740, Losses: rotation = 130821.11664869636 \n",
      "Iteration = 1750, Losses: rotation = 130821.17888447628 \n",
      "Iteration = 1760, Losses: rotation = 130821.23016423633 \n",
      "Iteration = 1770, Losses: rotation = 130821.27448579925 \n",
      "Iteration = 1780, Losses: rotation = 130821.31168222558 \n",
      "Iteration = 1790, Losses: rotation = 130821.33949525253 \n",
      "Iteration = 1800, Losses: rotation = 130821.37023376414 \n",
      "Iteration = 1810, Losses: rotation = 130821.38961102668 \n",
      "Iteration = 1820, Losses: rotation = 130821.40082128384 \n",
      "Iteration = 1830, Losses: rotation = 130821.41724883496 \n",
      "Iteration = 1840, Losses: rotation = 130821.42320159766 \n",
      "Iteration = 1850, Losses: rotation = 130821.42493877883 \n",
      "Iteration = 1860, Losses: rotation = 130821.41862181424 \n",
      "Iteration = 1870, Losses: rotation = 130821.41475877905 \n",
      "Iteration = 1880, Losses: rotation = 130821.40532253336 \n",
      "Iteration = 1890, Losses: rotation = 130821.38816125001 \n",
      "Iteration = 1900, Losses: rotation = 130821.37578510829 \n",
      "Iteration = 1910, Losses: rotation = 130821.35771873512 \n",
      "Iteration = 1920, Losses: rotation = 130821.33635481317 \n",
      "Iteration = 1930, Losses: rotation = 130821.31052399761 \n",
      "Iteration = 1940, Losses: rotation = 130821.28621233084 \n",
      "Iteration = 1950, Losses: rotation = 130821.25493071481 \n",
      "Iteration = 1960, Losses: rotation = 130821.22328060123 \n",
      "Iteration = 1970, Losses: rotation = 130821.19826992502 \n",
      "Iteration = 1980, Losses: rotation = 130821.15990048999 \n",
      "Iteration = 1990, Losses: rotation = 130821.12508349773 \n",
      "Iteration = 2000, Losses: rotation = 130821.08648251608 \n",
      "Iteration = 2010, Losses: rotation = 130821.05427927864 \n",
      "Iteration = 2020, Losses: rotation = 130821.016913038 \n",
      "Iteration = 2030, Losses: rotation = 130820.97681781574 \n",
      "Iteration = 2040, Losses: rotation = 130820.92926563486 \n",
      "Iteration = 2050, Losses: rotation = 130820.89206085938 \n",
      "Iteration = 2060, Losses: rotation = 130820.84787608153 \n",
      "Iteration = 2070, Losses: rotation = 130820.80399682718 \n",
      "Iteration = 2080, Losses: rotation = 130820.76720922966 \n",
      "Iteration = 2090, Losses: rotation = 130820.7168396092 \n",
      "Iteration = 2100, Losses: rotation = 130820.67607832688 \n",
      "Iteration = 2110, Losses: rotation = 130820.63007838253 \n",
      "Iteration = 2120, Losses: rotation = 130820.58515930291 \n",
      "Iteration = 2130, Losses: rotation = 130820.53912338137 \n",
      "Iteration = 2140, Losses: rotation = 130820.49283329648 \n",
      "Iteration = 2150, Losses: rotation = 130820.44787474428 \n",
      "Iteration = 2160, Losses: rotation = 130820.40471844704 \n",
      "Iteration = 2170, Losses: rotation = 130820.36245793352 \n",
      "Iteration = 2180, Losses: rotation = 130820.31110977042 \n",
      "Iteration = 2190, Losses: rotation = 130820.26883052551 \n",
      "Iteration = 2200, Losses: rotation = 130820.22074554875 \n",
      "Iteration = 2210, Losses: rotation = 130820.17572007 \n",
      "Iteration = 2220, Losses: rotation = 130820.13252268359 \n",
      "Iteration = 2230, Losses: rotation = 130820.08509395139 \n",
      "Iteration = 2240, Losses: rotation = 130820.04481235339 \n",
      "Iteration = 2250, Losses: rotation = 130819.99740451924 \n",
      "Iteration = 2260, Losses: rotation = 130819.9535083714 \n",
      "Iteration = 2270, Losses: rotation = 130819.91513241829 \n",
      "Iteration = 2280, Losses: rotation = 130819.87118925923 \n",
      "Iteration = 2290, Losses: rotation = 130819.8264876604 \n",
      "Iteration = 2300, Losses: rotation = 130819.78193318713 \n",
      "Iteration = 2310, Losses: rotation = 130819.74533032776 \n",
      "Iteration = 2320, Losses: rotation = 130819.70019541896 \n",
      "Iteration = 2330, Losses: rotation = 130819.66148593137 \n",
      "Iteration = 2340, Losses: rotation = 130819.62229974422 \n",
      "Iteration = 2350, Losses: rotation = 130819.57861792049 \n",
      "Iteration = 2360, Losses: rotation = 130819.535715321 \n",
      "Iteration = 2370, Losses: rotation = 130819.50084971939 \n",
      "Iteration = 2380, Losses: rotation = 130819.46167735776 \n",
      "Iteration = 2390, Losses: rotation = 130819.4241128054 \n",
      "Iteration = 2400, Losses: rotation = 130819.38593694761 \n",
      "Iteration = 2410, Losses: rotation = 130819.34790681052 \n",
      "Iteration = 2420, Losses: rotation = 130819.30973437814 \n",
      "Iteration = 2430, Losses: rotation = 130819.27843527445 \n",
      "Iteration = 2440, Losses: rotation = 130819.24328433053 \n",
      "Iteration = 2450, Losses: rotation = 130819.20605434284 \n",
      "Iteration = 2460, Losses: rotation = 130819.17112068854 \n",
      "Iteration = 2470, Losses: rotation = 130819.1370499682 \n",
      "Iteration = 2480, Losses: rotation = 130819.09701649439 \n",
      "Iteration = 2490, Losses: rotation = 130819.07092551875 \n",
      "Iteration = 2500, Losses: rotation = 130819.03702338003 \n",
      "Iteration = 2510, Losses: rotation = 130819.00424636886 \n",
      "Iteration = 2520, Losses: rotation = 130818.9741827087 \n",
      "Iteration = 2530, Losses: rotation = 130818.93976918755 \n",
      "Iteration = 2540, Losses: rotation = 130818.90851531264 \n",
      "Iteration = 2550, Losses: rotation = 130818.88186177572 \n",
      "Iteration = 2560, Losses: rotation = 130818.85282725153 \n",
      "Iteration = 2570, Losses: rotation = 130818.82507835174 \n",
      "Iteration = 2580, Losses: rotation = 130818.7971360029 \n",
      "Iteration = 2590, Losses: rotation = 130818.76602017651 \n",
      "Iteration = 2600, Losses: rotation = 130818.74114067084 \n",
      "Iteration = 2610, Losses: rotation = 130818.71452288274 \n",
      "Iteration = 2620, Losses: rotation = 130818.68447062673 \n",
      "Iteration = 2630, Losses: rotation = 130818.65843800863 \n",
      "Iteration = 2640, Losses: rotation = 130818.63221713065 \n",
      "Iteration = 2650, Losses: rotation = 130818.61091257178 \n",
      "Iteration = 2660, Losses: rotation = 130818.58683961615 \n",
      "Iteration = 2670, Losses: rotation = 130818.56333057175 \n",
      "Iteration = 2680, Losses: rotation = 130818.53634866841 \n",
      "Iteration = 2690, Losses: rotation = 130818.51249399438 \n",
      "Iteration = 2700, Losses: rotation = 130818.48824871118 \n",
      "Iteration = 2710, Losses: rotation = 130818.46980846045 \n",
      "Iteration = 2720, Losses: rotation = 130818.44509672363 \n",
      "Iteration = 2730, Losses: rotation = 130818.42349653912 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 2740, Losses: rotation = 130818.40615716681 \n",
      "Iteration = 2750, Losses: rotation = 130818.38263900731 \n",
      "Iteration = 2760, Losses: rotation = 130818.36154983887 \n",
      "Iteration = 2770, Losses: rotation = 130818.33832373712 \n",
      "Iteration = 2780, Losses: rotation = 130818.31887674086 \n",
      "Iteration = 2790, Losses: rotation = 130818.30109828427 \n",
      "Iteration = 2800, Losses: rotation = 130818.28359731312 \n",
      "Iteration = 2810, Losses: rotation = 130818.2617930623 \n",
      "Iteration = 2820, Losses: rotation = 130818.24811637467 \n",
      "Iteration = 2830, Losses: rotation = 130818.22806080291 \n",
      "Iteration = 2840, Losses: rotation = 130818.21135160892 \n",
      "Iteration = 2850, Losses: rotation = 130818.19624752119 \n",
      "Iteration = 2860, Losses: rotation = 130818.17802910373 \n",
      "Iteration = 2870, Losses: rotation = 130818.15942187478 \n",
      "Iteration = 2880, Losses: rotation = 130818.1435739379 \n",
      "Iteration = 2890, Losses: rotation = 130818.12473854085 \n",
      "Iteration = 2900, Losses: rotation = 130818.11638031172 \n",
      "Iteration = 2910, Losses: rotation = 130818.10216401148 \n",
      "Iteration = 2920, Losses: rotation = 130818.07890041359 \n",
      "Iteration = 2930, Losses: rotation = 130818.06398140003 \n",
      "Iteration = 2940, Losses: rotation = 130818.05224304266 \n",
      "Iteration = 2950, Losses: rotation = 130818.0351694344 \n",
      "Iteration = 2960, Losses: rotation = 130818.02575420955 \n",
      "Iteration = 2970, Losses: rotation = 130818.01158815496 \n",
      "Iteration = 2980, Losses: rotation = 130817.99949041172 \n",
      "Iteration = 2990, Losses: rotation = 130817.98540761763 \n",
      "Iteration = 3000, Losses: rotation = 130817.97412064309 \n",
      "Reconstrution Loss: 400.2976989746094 \n",
      "\n",
      "Loss: 130817.97119630197 \n",
      "\n",
      "Transpose: 4.531880767899565e-06 \n",
      "\n",
      "Distance to axis-aligned solution: 0.0030926255982762995 \n",
      "\n",
      "Distance to optimal subspace): 2.861022949662839e-07 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Define the model ####\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#### DEFINE MODEL #####\n",
    "model_dict = dict(\n",
    "    model_name='rotation',\n",
    "    model_type='rotation',\n",
    "    model_class=LinearAE,\n",
    "    extra_model_args = {'weight_reg_type':'convex_cluster', 'gauss_coef':1.0, 'neighbors':None},\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    init_scale=0.0001,\n",
    "    optim_class=torch.optim.SGD,\n",
    "    extra_optim_args={'momentum': 0.9, 'nesterov': True},\n",
    "    lr=0.0001,\n",
    "    train_itr=1000,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "\n",
    "# model config contains the model \n",
    "model_config = ModelConfig(\n",
    "        model_name=model_dict['model_name'],\n",
    "        model_type=model_dict['model_type'],\n",
    "        model_class=model_dict['model_class'],\n",
    "        input_dim=model_dict['input_dim'], \n",
    "        hidden_dim=model_dict['hidden_dim'],\n",
    "        init_scale=model_dict['init_scale'],\n",
    "        extra_model_args=model_dict['extra_model_args'],\n",
    "        optim_class=model_dict['optim_class'],\n",
    "        lr=model_dict['lr'],\n",
    "        extra_optim_args=model_dict['extra_optim_args']\n",
    "    )\n",
    "\n",
    "print(model_dict,'\\n')\n",
    "print(model_config.get_model(),'\\n')\n",
    "print(model_config.get_optimizer())\n",
    "\n",
    "print('Transpose:', metric_transpose_theorem(model_config.get_model()),'\\n') # how close encoder and decoder.T are \n",
    "print('Distance to axis-aligned solution:', metric_alignment(model_config.get_model(), data.eigvectors),'\\n') # alignment of decoder columns to ground truth eigenvectors\n",
    "print('Distance to optimal subspace):', metric_subspace(model_config.get_model(), data.eigvectors, data.eigs),'\\n')\n",
    "\n",
    "\n",
    "\n",
    "modelIn = model_config.get_model()\n",
    "print('Reconstrution Loss:', metric_recon_loss(modelIn, loader),'\\n') # full batch loss\n",
    "print('Loss:', metric_loss(modelIn, loader),'\\n')\n",
    "print('Transpose:', metric_transpose_theorem(modelIn),'\\n') # how close encoder and decoder.T are \n",
    "print('Distance to axis-aligned solution:', metric_alignment(modelIn, data.eigvectors),'\\n') # alignment of decoder columns to ground truth eigenvectors\n",
    "print('Distance to optimal subspace):', metric_subspace(modelIn, data.eigvectors, data.eigs),'\\n')\n",
    "\n",
    "model_config.get_model().cc_lambda=10.0\n",
    "trained_model = train_models(data_loader=loader, train_itr=3000, metrics_dict=None, model_configs=model_config)\n",
    "# trained_model = train_models(data_loader=loader, train_itr=model_dict['train_itr'], metrics_dict=None, model_configs=model_config)\n",
    "\n",
    "modelIn = model_config.get_model()\n",
    "print('Reconstrution Loss:', metric_recon_loss(modelIn, loader),'\\n') # full batch loss\n",
    "print('Loss:', metric_loss(modelIn, loader),'\\n')\n",
    "print('Transpose:', metric_transpose_theorem(modelIn),'\\n') # how close encoder and decoder.T are \n",
    "print('Distance to axis-aligned solution:', metric_alignment(modelIn, data.eigvectors),'\\n') # alignment of decoder columns to ground truth eigenvectors\n",
    "print('Distance to optimal subspace):', metric_subspace(modelIn, data.eigvectors, data.eigs),'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b74bab",
   "metadata": {},
   "source": [
    "### TRAIN A MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a9b697",
   "metadata": {},
   "source": [
    "####  Model #1: Get the data and define the model - rotation with 400 hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b512ea4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'rotation', 'model_type': 'rotation', 'model_class': <class '__main__.LinearAE'>, 'extra_model_args': {'weight_reg_type': None}, 'input_dim': 1000, 'hidden_dim': 400, 'init_scale': 0.0001, 'optim_class': <class 'torch.optim.sgd.SGD'>, 'extra_optim_args': {'momentum': 0.9, 'nesterov': True}, 'lr': 0.0001, 'train_itr': 1000, 'seed': 1234} \n",
      "\n",
      "LinearAE(\n",
      "  (encoder): Linear(in_features=1000, out_features=400, bias=False)\n",
      "  (decoder): Linear(in_features=400, out_features=1000, bias=False)\n",
      ") \n",
      "\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0\n",
      ")\n",
      "Transpose: 1.9994410686194896e-05 \n",
      "\n",
      "Distance to axis-aligned solution: 0.9897644591560325 \n",
      "\n",
      "Distance to optimal subspace): 0.6001819992065429 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### GET DATA ####\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed=1234\n",
    "# set random seed\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "input_dim = 1000\n",
    "hidden_dim = 400\n",
    "\n",
    "n_data = 5000\n",
    "batch_size = n_data\n",
    "\n",
    "max_sv = float(input_dim) * 0.1\n",
    "min_sv = 1.0\n",
    "sigma = 0.5\n",
    "\n",
    "gt_data = DataGeneratorPCA(input_dim, hidden_dim, min_sv=min_sv, max_sv=max_sv, total=n_data)\n",
    "data = DataGeneratorPCA(input_dim, hidden_dim, load_data=gt_data.x_sample)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#### Define the model ####\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#### DEFINE MODEL #####\n",
    "model_dict = dict(\n",
    "    model_name='rotation',\n",
    "    model_type='rotation',\n",
    "    model_class=LinearAE,\n",
    "    extra_model_args = {\"weight_reg_type\": None},\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    init_scale=0.0001,\n",
    "    optim_class=torch.optim.SGD,\n",
    "    extra_optim_args={'momentum': 0.9, 'nesterov': True},\n",
    "    lr=0.0001,\n",
    "#     optim_class=torch.optim.Adam,\n",
    "#     extra_optim_args={},\n",
    "#     lr=0.0003,\n",
    "    train_itr=1000,#50000,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# model config contains the model \n",
    "model_config = ModelConfig(\n",
    "        model_name=model_dict['model_name'],\n",
    "        model_type=model_dict['model_type'],\n",
    "        model_class=model_dict['model_class'],\n",
    "        input_dim=model_dict['input_dim'], \n",
    "        hidden_dim=model_dict['hidden_dim'],\n",
    "        init_scale=model_dict['init_scale'],\n",
    "        extra_model_args=model_dict['extra_model_args'],\n",
    "        optim_class=model_dict['optim_class'],\n",
    "        lr=model_dict['lr'],\n",
    "        extra_optim_args=model_dict['extra_optim_args']\n",
    "    )\n",
    "\n",
    "print(model_dict,'\\n')\n",
    "print(model_config.get_model(),'\\n')\n",
    "print(model_config.get_optimizer())\n",
    "\n",
    "print('Transpose:', metric_transpose_theorem(model_config.get_model()),'\\n') # how close encoder and decoder.T are \n",
    "print('Distance to axis-aligned solution:', metric_alignment(model_config.get_model(), data.eigvectors),'\\n') # alignment of decoder columns to ground truth eigenvectors\n",
    "print('Distance to optimal subspace):', metric_subspace(model_config.get_model(), data.eigvectors, data.eigs),'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea3b00",
   "metadata": {},
   "source": [
    "#### Model #1: Run the model - rotation with 400 hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c308871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstrution Loss: 47806.57421875 \n",
      "\n",
      "Loss: 49319.0234375 \n",
      "\n",
      "Transpose: 0.003536132350564003 \n",
      "\n",
      "Distance to axis-aligned solution: 0.09904575485510528 \n",
      "\n",
      "Distance to optimal subspace): 3.8146972658470446e-07 \n",
      "\n",
      "Iteration = 1, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 10, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 20, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 30, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 40, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 50, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 60, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 70, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 80, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 90, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 100, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 110, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 120, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 130, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 140, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 150, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 160, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 170, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 180, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 190, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 200, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 210, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 220, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 230, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 240, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 250, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 260, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 270, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 280, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 290, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 300, Losses: nd_expectation = 49319.015625 \n",
      "Iteration = 310, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 320, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 330, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 340, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 350, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 360, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 370, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 380, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 390, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 400, Losses: nd_expectation = 49319.015625 \n",
      "Iteration = 410, Losses: nd_expectation = 49319.015625 \n",
      "Iteration = 420, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 430, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 440, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 450, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 460, Losses: nd_expectation = 49319.015625 \n",
      "Iteration = 470, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 480, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 490, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 500, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 510, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 520, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 530, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 540, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 550, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 560, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 570, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 580, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 590, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 600, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 610, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 620, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 630, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 640, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 650, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 660, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 670, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 680, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 690, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 700, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 710, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 720, Losses: nd_expectation = 49319.015625 \n",
      "Iteration = 730, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 740, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 750, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 760, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 770, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 780, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 790, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 800, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 810, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 820, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 830, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 840, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 850, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 860, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 870, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 880, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 890, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 900, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 910, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 920, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 930, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 940, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 950, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 960, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 970, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 980, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 990, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 1000, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 1010, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 1020, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1030, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1040, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 1050, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 1060, Losses: nd_expectation = 49319.046875 \n",
      "Iteration = 1070, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1080, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 1090, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 1100, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 1110, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1120, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 1130, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 1140, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 1150, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1160, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1170, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1180, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 1190, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1200, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1210, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 1220, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 1230, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 1240, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1250, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 1260, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1270, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1280, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 1290, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1300, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1310, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 1320, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1330, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 1340, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1350, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1360, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1370, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1380, Losses: nd_expectation = 49319.03125 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 1390, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1400, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1410, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1420, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 1430, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 1440, Losses: nd_expectation = 49319.046875 \n",
      "Iteration = 1450, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1460, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1470, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1480, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1490, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1500, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1510, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1520, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1530, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1540, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1550, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 1560, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 1570, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 1580, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1590, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1600, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1610, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1620, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1630, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1640, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1650, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1660, Losses: nd_expectation = 49319.05078125 \n",
      "Iteration = 1670, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 1680, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1690, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 1700, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 1710, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 1720, Losses: nd_expectation = 49319.05859375 \n",
      "Iteration = 1730, Losses: nd_expectation = 49319.046875 \n",
      "Iteration = 1740, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1750, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 1760, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1770, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 1780, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 1790, Losses: nd_expectation = 49319.046875 \n",
      "Iteration = 1800, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1810, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1820, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1830, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1840, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1850, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 1860, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 1870, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1880, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1890, Losses: nd_expectation = 49319.046875 \n",
      "Iteration = 1900, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 1910, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 1920, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1930, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 1940, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 1950, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 1960, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1970, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 1980, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 1990, Losses: nd_expectation = 49319.0546875 \n",
      "Iteration = 2000, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2010, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 2020, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 2030, Losses: nd_expectation = 49319.0546875 \n",
      "Iteration = 2040, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2050, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2060, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2070, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2080, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2090, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2100, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2110, Losses: nd_expectation = 49319.046875 \n",
      "Iteration = 2120, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2130, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2140, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2150, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2160, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2170, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 2180, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2190, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2200, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2210, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2220, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2230, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2240, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2250, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2260, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2270, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2280, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2290, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2300, Losses: nd_expectation = 49319.0546875 \n",
      "Iteration = 2310, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2320, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2330, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2340, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2350, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2360, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2370, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2380, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2390, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2400, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2410, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2420, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 2430, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2440, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2450, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2460, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2470, Losses: nd_expectation = 49319.046875 \n",
      "Iteration = 2480, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2490, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2500, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2510, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2520, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2530, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2540, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2550, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2560, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2570, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2580, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2590, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 2600, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2610, Losses: nd_expectation = 49319.05078125 \n",
      "Iteration = 2620, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2630, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2640, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 2650, Losses: nd_expectation = 49319.046875 \n",
      "Iteration = 2660, Losses: nd_expectation = 49319.0546875 \n",
      "Iteration = 2670, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2680, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 2690, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 2700, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2710, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2720, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2730, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2740, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2750, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2760, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2770, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2780, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2790, Losses: nd_expectation = 49319.0390625 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 2800, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2810, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2820, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2830, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2840, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2850, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2860, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2870, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2880, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2890, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2900, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2910, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2920, Losses: nd_expectation = 49319.046875 \n",
      "Iteration = 2930, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 2940, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2950, Losses: nd_expectation = 49319.046875 \n",
      "Iteration = 2960, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2970, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2980, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2990, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 3000, Losses: nd_expectation = 49319.03515625 \n",
      "Reconstrution Loss: 47806.62890625 \n",
      "\n",
      "Loss: 49319.03515625 \n",
      "\n",
      "Transpose: 0.00029654598329216243 \n",
      "\n",
      "Distance to axis-aligned solution: 0.025499498070972848 \n",
      "\n",
      "Distance to optimal subspace): 8.583068847878295e-07 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelIn = model_config.get_model()\n",
    "print('Reconstrution Loss:', metric_recon_loss(modelIn, loader),'\\n') # full batch loss\n",
    "print('Loss:', metric_loss(modelIn, loader),'\\n')\n",
    "print('Transpose:', metric_transpose_theorem(modelIn),'\\n') # how close encoder and decoder.T are \n",
    "print('Distance to axis-aligned solution:', metric_alignment(modelIn, data.eigvectors),'\\n') # alignment of decoder columns to ground truth eigenvectors\n",
    "print('Distance to optimal subspace):', metric_subspace(modelIn, data.eigvectors, data.eigs),'\\n')\n",
    "\n",
    "trained_model = train_models(data_loader=loader, train_itr=model_dict['train_itr'], metrics_dict=None, model_configs=model_config)\n",
    "\n",
    "modelIn = model_config.get_model()\n",
    "print('Reconstrution Loss:', metric_recon_loss(modelIn, loader),'\\n') # full batch loss\n",
    "print('Loss:', metric_loss(modelIn, loader),'\\n')\n",
    "print('Transpose:', metric_transpose_theorem(modelIn),'\\n') # how close encoder and decoder.T are \n",
    "print('Distance to axis-aligned solution:', metric_alignment(modelIn, data.eigvectors),'\\n') # alignment of decoder columns to ground truth eigenvectors\n",
    "print('Distance to optimal subspace):', metric_subspace(modelIn, data.eigvectors, data.eigs),'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2212e8e",
   "metadata": {},
   "source": [
    "#### Model #2: Get the data and define the model - rotation with 50 hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82fd3dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'rotation', 'model_type': 'rotation', 'model_class': <class '__main__.LinearAE'>, 'extra_model_args': {'weight_reg_type': None}, 'input_dim': 1000, 'hidden_dim': 50, 'init_scale': 0.0001, 'optim_class': <class 'torch.optim.sgd.SGD'>, 'extra_optim_args': {'momentum': 0.9, 'nesterov': True}, 'lr': 0.0001, 'train_itr': 1000, 'seed': 1234} \n",
      "\n",
      "LinearAE(\n",
      "  (encoder): Linear(in_features=1000, out_features=50, bias=False)\n",
      "  (decoder): Linear(in_features=50, out_features=1000, bias=False)\n",
      ") \n",
      "\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0\n",
      ")\n",
      "Transpose: 1.9993053283542393e-05 \n",
      "\n",
      "Distance to axis-aligned solution: 0.993878737828118 \n",
      "\n",
      "Distance to optimal subspace): 0.9511795520782471 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### GET DATA ####\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed=1234\n",
    "# set random seed\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "input_dim = 1000\n",
    "hidden_dim = 50\n",
    "\n",
    "n_data = 5000\n",
    "batch_size = n_data\n",
    "\n",
    "max_sv = float(input_dim) * 0.1\n",
    "min_sv = 1.0\n",
    "sigma = 0.5\n",
    "\n",
    "gt_data = DataGeneratorPCA(input_dim, hidden_dim, min_sv=min_sv, max_sv=max_sv, total=n_data)\n",
    "data = DataGeneratorPCA(input_dim, hidden_dim, load_data=gt_data.x_sample)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#### Define the model ####\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#### DEFINE MODEL #####\n",
    "model_dict = dict(\n",
    "    model_name='rotation',\n",
    "    model_type='rotation',\n",
    "    model_class=LinearAE,\n",
    "    extra_model_args = {\"weight_reg_type\": None},\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    init_scale=0.0001,\n",
    "    optim_class=torch.optim.SGD,\n",
    "    extra_optim_args={'momentum': 0.9, 'nesterov': True},\n",
    "    lr=0.0001,\n",
    "#     optim_class=torch.optim.Adam,\n",
    "#     extra_optim_args={},\n",
    "#     lr=0.0003,\n",
    "    train_itr=1000,#50000,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# model config contains the model \n",
    "model_config = ModelConfig(\n",
    "        model_name=model_dict['model_name'],\n",
    "        model_type=model_dict['model_type'],\n",
    "        model_class=model_dict['model_class'],\n",
    "        input_dim=model_dict['input_dim'], \n",
    "        hidden_dim=model_dict['hidden_dim'],\n",
    "        init_scale=model_dict['init_scale'],\n",
    "        extra_model_args=model_dict['extra_model_args'],\n",
    "        optim_class=model_dict['optim_class'],\n",
    "        lr=model_dict['lr'],\n",
    "        extra_optim_args=model_dict['extra_optim_args']\n",
    "    )\n",
    "\n",
    "print(model_dict,'\\n')\n",
    "print(model_config.get_model(),'\\n')\n",
    "print(model_config.get_optimizer())\n",
    "\n",
    "print('Transpose:', metric_transpose_theorem(model_config.get_model()),'\\n') # how close encoder and decoder.T are \n",
    "print('Distance to axis-aligned solution:', metric_alignment(model_config.get_model(), data.eigvectors),'\\n') # alignment of decoder columns to ground truth eigenvectors\n",
    "print('Distance to optimal subspace):', metric_subspace(model_config.get_model(), data.eigvectors, data.eigs),'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046dfc06",
   "metadata": {},
   "source": [
    "#### Model #2: Run the model - rotation with 50 hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59b24366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstrution Loss: 50555.9375 \n",
      "\n",
      "Loss: 50555.9375 \n",
      "\n",
      "Transpose: 1.9993053283542393e-05 \n",
      "\n",
      "Distance to axis-aligned solution: 0.993878737828118 \n",
      "\n",
      "Distance to optimal subspace): 0.9511795520782471 \n",
      "\n",
      "Iteration = 1, Losses: rotation = 50555.9375 \n",
      "Iteration = 10, Losses: rotation = 50555.86328125 \n",
      "Iteration = 20, Losses: rotation = 50555.3125 \n",
      "Iteration = 30, Losses: rotation = 50549.6328125 \n",
      "Iteration = 40, Losses: rotation = 50485.734375 \n",
      "Iteration = 50, Losses: rotation = 49784.1875 \n",
      "Iteration = 60, Losses: rotation = 46384.1953125 \n",
      "Iteration = 70, Losses: rotation = 44725.10546875 \n",
      "Iteration = 80, Losses: rotation = 44449.55859375 \n",
      "Iteration = 90, Losses: rotation = 44315.09765625 \n",
      "Iteration = 100, Losses: rotation = 44242.43359375 \n",
      "Iteration = 110, Losses: rotation = 44198.40234375 \n",
      "Iteration = 120, Losses: rotation = 44166.01171875 \n",
      "Iteration = 130, Losses: rotation = 44141.96875 \n",
      "Iteration = 140, Losses: rotation = 44123.3984375 \n",
      "Iteration = 150, Losses: rotation = 44108.734375 \n",
      "Iteration = 160, Losses: rotation = 44097.0 \n",
      "Iteration = 170, Losses: rotation = 44087.4609375 \n",
      "Iteration = 180, Losses: rotation = 44079.62890625 \n",
      "Iteration = 190, Losses: rotation = 44073.125 \n",
      "Iteration = 200, Losses: rotation = 44067.6640625 \n",
      "Iteration = 210, Losses: rotation = 44063.0546875 \n",
      "Iteration = 220, Losses: rotation = 44059.11328125 \n",
      "Iteration = 230, Losses: rotation = 44055.7265625 \n",
      "Iteration = 240, Losses: rotation = 44052.796875 \n",
      "Iteration = 250, Losses: rotation = 44050.25390625 \n",
      "Iteration = 260, Losses: rotation = 44048.0234375 \n",
      "Iteration = 270, Losses: rotation = 44046.06640625 \n",
      "Iteration = 280, Losses: rotation = 44044.34375 \n",
      "Iteration = 290, Losses: rotation = 44042.8203125 \n",
      "Iteration = 300, Losses: rotation = 44041.4609375 \n",
      "Iteration = 310, Losses: rotation = 44040.26171875 \n",
      "Iteration = 320, Losses: rotation = 44039.18359375 \n",
      "Iteration = 330, Losses: rotation = 44038.22265625 \n",
      "Iteration = 340, Losses: rotation = 44037.35546875 \n",
      "Iteration = 350, Losses: rotation = 44036.578125 \n",
      "Iteration = 360, Losses: rotation = 44035.87890625 \n",
      "Iteration = 370, Losses: rotation = 44035.2421875 \n",
      "Iteration = 380, Losses: rotation = 44034.6640625 \n",
      "Iteration = 390, Losses: rotation = 44034.14453125 \n",
      "Iteration = 400, Losses: rotation = 44033.66796875 \n",
      "Iteration = 410, Losses: rotation = 44033.23046875 \n",
      "Iteration = 420, Losses: rotation = 44032.828125 \n",
      "Iteration = 430, Losses: rotation = 44032.4609375 \n",
      "Iteration = 440, Losses: rotation = 44032.1171875 \n",
      "Iteration = 450, Losses: rotation = 44031.8046875 \n",
      "Iteration = 460, Losses: rotation = 44031.51171875 \n",
      "Iteration = 470, Losses: rotation = 44031.2421875 \n",
      "Iteration = 480, Losses: rotation = 44030.984375 \n",
      "Iteration = 490, Losses: rotation = 44030.75390625 \n",
      "Iteration = 500, Losses: rotation = 44030.53515625 \n",
      "Iteration = 510, Losses: rotation = 44030.328125 \n",
      "Iteration = 520, Losses: rotation = 44030.1328125 \n",
      "Iteration = 530, Losses: rotation = 44029.953125 \n",
      "Iteration = 540, Losses: rotation = 44029.77734375 \n",
      "Iteration = 550, Losses: rotation = 44029.61328125 \n",
      "Iteration = 560, Losses: rotation = 44029.45703125 \n",
      "Iteration = 570, Losses: rotation = 44029.3125 \n",
      "Iteration = 580, Losses: rotation = 44029.17578125 \n",
      "Iteration = 590, Losses: rotation = 44029.0390625 \n",
      "Iteration = 600, Losses: rotation = 44028.9140625 \n",
      "Iteration = 610, Losses: rotation = 44028.7890625 \n",
      "Iteration = 620, Losses: rotation = 44028.6796875 \n",
      "Iteration = 630, Losses: rotation = 44028.57421875 \n",
      "Iteration = 640, Losses: rotation = 44028.46875 \n",
      "Iteration = 650, Losses: rotation = 44028.36328125 \n",
      "Iteration = 660, Losses: rotation = 44028.265625 \n",
      "Iteration = 670, Losses: rotation = 44028.171875 \n",
      "Iteration = 680, Losses: rotation = 44028.078125 \n",
      "Iteration = 690, Losses: rotation = 44027.99609375 \n",
      "Iteration = 700, Losses: rotation = 44027.91796875 \n",
      "Iteration = 710, Losses: rotation = 44027.83203125 \n",
      "Iteration = 720, Losses: rotation = 44027.75390625 \n",
      "Iteration = 730, Losses: rotation = 44027.6796875 \n",
      "Iteration = 740, Losses: rotation = 44027.609375 \n",
      "Iteration = 750, Losses: rotation = 44027.5390625 \n",
      "Iteration = 760, Losses: rotation = 44027.47265625 \n",
      "Iteration = 770, Losses: rotation = 44027.4140625 \n",
      "Iteration = 780, Losses: rotation = 44027.34765625 \n",
      "Iteration = 790, Losses: rotation = 44027.28125 \n",
      "Iteration = 800, Losses: rotation = 44027.2265625 \n",
      "Iteration = 810, Losses: rotation = 44027.16796875 \n",
      "Iteration = 820, Losses: rotation = 44027.11328125 \n",
      "Iteration = 830, Losses: rotation = 44027.0625 \n",
      "Iteration = 840, Losses: rotation = 44027.01171875 \n",
      "Iteration = 850, Losses: rotation = 44026.9609375 \n",
      "Iteration = 860, Losses: rotation = 44026.9140625 \n",
      "Iteration = 870, Losses: rotation = 44026.8671875 \n",
      "Iteration = 880, Losses: rotation = 44026.82421875 \n",
      "Iteration = 890, Losses: rotation = 44026.77734375 \n",
      "Iteration = 900, Losses: rotation = 44026.734375 \n",
      "Iteration = 910, Losses: rotation = 44026.69921875 \n",
      "Iteration = 920, Losses: rotation = 44026.66015625 \n",
      "Iteration = 930, Losses: rotation = 44026.6171875 \n",
      "Iteration = 940, Losses: rotation = 44026.57421875 \n",
      "Iteration = 950, Losses: rotation = 44026.54296875 \n",
      "Iteration = 960, Losses: rotation = 44026.515625 \n",
      "Iteration = 970, Losses: rotation = 44026.48046875 \n",
      "Iteration = 980, Losses: rotation = 44026.4453125 \n",
      "Iteration = 990, Losses: rotation = 44026.4140625 \n",
      "Iteration = 1000, Losses: rotation = 44026.37890625 \n",
      "Reconstrution Loss: 44026.37890625 \n",
      "\n",
      "Loss: 44026.37890625 \n",
      "\n",
      "Transpose: 6.9371220888569954e-06 \n",
      "\n",
      "Distance to axis-aligned solution: 0.6839896868942504 \n",
      "\n",
      "Distance to optimal subspace): 0.01873413085937503 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelIn = model_config.get_model()\n",
    "print('Reconstrution Loss:', metric_recon_loss(modelIn, loader),'\\n') # full batch loss\n",
    "print('Loss:', metric_loss(modelIn, loader),'\\n')\n",
    "print('Transpose:', metric_transpose_theorem(modelIn),'\\n') # how close encoder and decoder.T are \n",
    "print('Distance to axis-aligned solution:', metric_alignment(modelIn, data.eigvectors),'\\n') # alignment of decoder columns to ground truth eigenvectors\n",
    "print('Distance to optimal subspace):', metric_subspace(modelIn, data.eigvectors, data.eigs),'\\n')\n",
    "\n",
    "trained_model = train_models(data_loader=loader, train_itr=1000, metrics_dict=None, model_configs=model_config)\n",
    "\n",
    "modelIn = model_config.get_model()\n",
    "print('Reconstrution Loss:', metric_recon_loss(modelIn, loader),'\\n') # full batch loss\n",
    "print('Loss:', metric_loss(modelIn, loader),'\\n')\n",
    "print('Transpose:', metric_transpose_theorem(modelIn),'\\n') # how close encoder and decoder.T are \n",
    "print('Distance to axis-aligned solution:', metric_alignment(modelIn, data.eigvectors),'\\n') # alignment of decoder columns to ground truth eigenvectors\n",
    "print('Distance to optimal subspace):', metric_subspace(modelIn, data.eigvectors, data.eigs),'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d51346",
   "metadata": {},
   "source": [
    "#### Model #3: Get the data and define the model - nested dropout with 40 hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b908d311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'nd_expectation', 'model_type': 'nested_dropout', 'model_class': <class '__main__.LinearAENestedDropout'>, 'extra_model_args': {'use_expectation': True}, 'input_dim': 1000, 'hidden_dim': 20, 'init_scale': 0.0001, 'optim_class': <class 'torch.optim.adam.Adam'>, 'extra_optim_args': {}, 'lr': 0.003, 'train_itr': 3000, 'seed': 1234} \n",
      "\n",
      "LinearAENestedDropout(\n",
      "  (encoder): Linear(in_features=1000, out_features=20, bias=False)\n",
      "  (decoder): Linear(in_features=20, out_features=1000, bias=False)\n",
      ") \n",
      "\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.003\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Transpose: 2.013526827795431e-05 \n",
      "\n",
      "Distance to axis-aligned solution: 0.9951107563416652 \n",
      "\n",
      "Distance to optimal subspace): 0.9793644726276398 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### GET DATA ####\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed=1234\n",
    "# set random seed\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "input_dim = 1000\n",
    "hidden_dim = 20\n",
    "\n",
    "n_data = 5000\n",
    "batch_size = n_data\n",
    "\n",
    "max_sv = float(input_dim) * 0.1\n",
    "min_sv = 1.0\n",
    "sigma = 0.5\n",
    "\n",
    "gt_data = DataGeneratorPCA(input_dim, hidden_dim, min_sv=min_sv, max_sv=max_sv, total=n_data)\n",
    "data = DataGeneratorPCA(input_dim, hidden_dim, load_data=gt_data.x_sample)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#### Define the model ####\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "#### DEFINE MODEL #####\n",
    "model_dict = dict(\n",
    "    model_name='nd_expectation',\n",
    "    model_type='nested_dropout',\n",
    "    model_class=LinearAENestedDropout,\n",
    "    extra_model_args = {'use_expectation': True},\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    init_scale=0.0001,\n",
    "    optim_class=torch.optim.Adam,\n",
    "    extra_optim_args={},\n",
    "    lr=0.003,\n",
    "    train_itr=3000,#50000,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# model config contains the model \n",
    "model_config = ModelConfig(\n",
    "        model_name=model_dict['model_name'],\n",
    "        model_type=model_dict['model_type'],\n",
    "        model_class=model_dict['model_class'],\n",
    "        input_dim=model_dict['input_dim'], \n",
    "        hidden_dim=model_dict['hidden_dim'],\n",
    "        init_scale=model_dict['init_scale'],\n",
    "        extra_model_args=model_dict['extra_model_args'],\n",
    "        optim_class=model_dict['optim_class'],\n",
    "        lr=model_dict['lr'],\n",
    "        extra_optim_args=model_dict['extra_optim_args']\n",
    "    )\n",
    "\n",
    "print(model_dict,'\\n')\n",
    "print(model_config.get_model(),'\\n')\n",
    "print(model_config.get_optimizer())\n",
    "\n",
    "print('Transpose:', metric_transpose_theorem(model_config.get_model()),'\\n') # how close encoder and decoder.T are \n",
    "print('Distance to axis-aligned solution:', metric_alignment(model_config.get_model(), data.eigvectors),'\\n') # alignment of decoder columns to ground truth eigenvectors\n",
    "print('Distance to optimal subspace):', metric_subspace(model_config.get_model(), data.eigvectors, data.eigs),'\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dde953",
   "metadata": {},
   "source": [
    "#### Model #3: Run the model - nested dropout with 40 hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ecb7cb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstrution Loss: 50555.9375 \n",
      "\n",
      "Loss: 50544.8828125 \n",
      "\n",
      "Transpose: 2.013526827795431e-05 \n",
      "\n",
      "Distance to axis-aligned solution: 0.9951107563416652 \n",
      "\n",
      "Distance to optimal subspace): 0.9793644726276398 \n",
      "\n",
      "Iteration = 1, Losses: nd_expectation = 50544.8828125 \n",
      "Iteration = 10, Losses: nd_expectation = 50005.375 \n",
      "Iteration = 20, Losses: nd_expectation = 49659.06640625 \n",
      "Iteration = 30, Losses: nd_expectation = 49504.6328125 \n",
      "Iteration = 40, Losses: nd_expectation = 49428.1875 \n",
      "Iteration = 50, Losses: nd_expectation = 49391.37109375 \n",
      "Iteration = 60, Losses: nd_expectation = 49371.125 \n",
      "Iteration = 70, Losses: nd_expectation = 49358.13671875 \n",
      "Iteration = 80, Losses: nd_expectation = 49350.11328125 \n",
      "Iteration = 90, Losses: nd_expectation = 49344.70703125 \n",
      "Iteration = 100, Losses: nd_expectation = 49340.89453125 \n",
      "Iteration = 110, Losses: nd_expectation = 49338.078125 \n",
      "Iteration = 120, Losses: nd_expectation = 49335.91796875 \n",
      "Iteration = 130, Losses: nd_expectation = 49334.1875 \n",
      "Iteration = 140, Losses: nd_expectation = 49332.765625 \n",
      "Iteration = 150, Losses: nd_expectation = 49331.5546875 \n",
      "Iteration = 160, Losses: nd_expectation = 49330.5234375 \n",
      "Iteration = 170, Losses: nd_expectation = 49329.625 \n",
      "Iteration = 180, Losses: nd_expectation = 49328.84375 \n",
      "Iteration = 190, Losses: nd_expectation = 49328.16015625 \n",
      "Iteration = 200, Losses: nd_expectation = 49327.55078125 \n",
      "Iteration = 210, Losses: nd_expectation = 49327.015625 \n",
      "Iteration = 220, Losses: nd_expectation = 49326.53515625 \n",
      "Iteration = 230, Losses: nd_expectation = 49326.09765625 \n",
      "Iteration = 240, Losses: nd_expectation = 49325.703125 \n",
      "Iteration = 250, Losses: nd_expectation = 49325.3359375 \n",
      "Iteration = 260, Losses: nd_expectation = 49325.0 \n",
      "Iteration = 270, Losses: nd_expectation = 49324.68359375 \n",
      "Iteration = 280, Losses: nd_expectation = 49324.390625 \n",
      "Iteration = 290, Losses: nd_expectation = 49324.11328125 \n",
      "Iteration = 300, Losses: nd_expectation = 49323.8515625 \n",
      "Iteration = 310, Losses: nd_expectation = 49323.60546875 \n",
      "Iteration = 320, Losses: nd_expectation = 49323.37109375 \n",
      "Iteration = 330, Losses: nd_expectation = 49323.15234375 \n",
      "Iteration = 340, Losses: nd_expectation = 49322.9453125 \n",
      "Iteration = 350, Losses: nd_expectation = 49322.74609375 \n",
      "Iteration = 360, Losses: nd_expectation = 49322.55859375 \n",
      "Iteration = 370, Losses: nd_expectation = 49322.37890625 \n",
      "Iteration = 380, Losses: nd_expectation = 49322.21484375 \n",
      "Iteration = 390, Losses: nd_expectation = 49322.0625 \n",
      "Iteration = 400, Losses: nd_expectation = 49321.91015625 \n",
      "Iteration = 410, Losses: nd_expectation = 49321.77734375 \n",
      "Iteration = 420, Losses: nd_expectation = 49321.6484375 \n",
      "Iteration = 430, Losses: nd_expectation = 49321.52734375 \n",
      "Iteration = 440, Losses: nd_expectation = 49321.4140625 \n",
      "Iteration = 450, Losses: nd_expectation = 49321.30859375 \n",
      "Iteration = 460, Losses: nd_expectation = 49321.21484375 \n",
      "Iteration = 470, Losses: nd_expectation = 49321.125 \n",
      "Iteration = 480, Losses: nd_expectation = 49321.04296875 \n",
      "Iteration = 490, Losses: nd_expectation = 49320.96484375 \n",
      "Iteration = 500, Losses: nd_expectation = 49320.89453125 \n",
      "Iteration = 510, Losses: nd_expectation = 49320.82421875 \n",
      "Iteration = 520, Losses: nd_expectation = 49320.76171875 \n",
      "Iteration = 530, Losses: nd_expectation = 49320.703125 \n",
      "Iteration = 540, Losses: nd_expectation = 49320.6484375 \n",
      "Iteration = 550, Losses: nd_expectation = 49320.59765625 \n",
      "Iteration = 560, Losses: nd_expectation = 49320.55078125 \n",
      "Iteration = 570, Losses: nd_expectation = 49320.50390625 \n",
      "Iteration = 580, Losses: nd_expectation = 49320.46484375 \n",
      "Iteration = 590, Losses: nd_expectation = 49320.421875 \n",
      "Iteration = 600, Losses: nd_expectation = 49320.3828125 \n",
      "Iteration = 610, Losses: nd_expectation = 49320.34375 \n",
      "Iteration = 620, Losses: nd_expectation = 49320.30859375 \n",
      "Iteration = 630, Losses: nd_expectation = 49320.27734375 \n",
      "Iteration = 640, Losses: nd_expectation = 49320.24609375 \n",
      "Iteration = 650, Losses: nd_expectation = 49320.21875 \n",
      "Iteration = 660, Losses: nd_expectation = 49320.1875 \n",
      "Iteration = 670, Losses: nd_expectation = 49320.16015625 \n",
      "Iteration = 680, Losses: nd_expectation = 49320.1328125 \n",
      "Iteration = 690, Losses: nd_expectation = 49320.10546875 \n",
      "Iteration = 700, Losses: nd_expectation = 49320.078125 \n",
      "Iteration = 710, Losses: nd_expectation = 49320.0546875 \n",
      "Iteration = 720, Losses: nd_expectation = 49320.03125 \n",
      "Iteration = 730, Losses: nd_expectation = 49320.0078125 \n",
      "Iteration = 740, Losses: nd_expectation = 49319.98828125 \n",
      "Iteration = 750, Losses: nd_expectation = 49319.96875 \n",
      "Iteration = 760, Losses: nd_expectation = 49319.9453125 \n",
      "Iteration = 770, Losses: nd_expectation = 49319.92578125 \n",
      "Iteration = 780, Losses: nd_expectation = 49319.90625 \n",
      "Iteration = 790, Losses: nd_expectation = 49319.88671875 \n",
      "Iteration = 800, Losses: nd_expectation = 49319.8671875 \n",
      "Iteration = 810, Losses: nd_expectation = 49319.84765625 \n",
      "Iteration = 820, Losses: nd_expectation = 49319.83203125 \n",
      "Iteration = 830, Losses: nd_expectation = 49319.81640625 \n",
      "Iteration = 840, Losses: nd_expectation = 49319.80078125 \n",
      "Iteration = 850, Losses: nd_expectation = 49319.78125 \n",
      "Iteration = 860, Losses: nd_expectation = 49319.76953125 \n",
      "Iteration = 870, Losses: nd_expectation = 49319.75 \n",
      "Iteration = 880, Losses: nd_expectation = 49319.73828125 \n",
      "Iteration = 890, Losses: nd_expectation = 49319.72265625 \n",
      "Iteration = 900, Losses: nd_expectation = 49319.70703125 \n",
      "Iteration = 910, Losses: nd_expectation = 49319.6953125 \n",
      "Iteration = 920, Losses: nd_expectation = 49319.6796875 \n",
      "Iteration = 930, Losses: nd_expectation = 49319.66796875 \n",
      "Iteration = 940, Losses: nd_expectation = 49319.65625 \n",
      "Iteration = 950, Losses: nd_expectation = 49319.640625 \n",
      "Iteration = 960, Losses: nd_expectation = 49319.62890625 \n",
      "Iteration = 970, Losses: nd_expectation = 49319.6171875 \n",
      "Iteration = 980, Losses: nd_expectation = 49319.6015625 \n",
      "Iteration = 990, Losses: nd_expectation = 49319.59375 \n",
      "Iteration = 1000, Losses: nd_expectation = 49319.58203125 \n",
      "Iteration = 1010, Losses: nd_expectation = 49319.56640625 \n",
      "Iteration = 1020, Losses: nd_expectation = 49319.55859375 \n",
      "Iteration = 1030, Losses: nd_expectation = 49319.546875 \n",
      "Iteration = 1040, Losses: nd_expectation = 49319.53515625 \n",
      "Iteration = 1050, Losses: nd_expectation = 49319.52734375 \n",
      "Iteration = 1060, Losses: nd_expectation = 49319.515625 \n",
      "Iteration = 1070, Losses: nd_expectation = 49319.50390625 \n",
      "Iteration = 1080, Losses: nd_expectation = 49319.49609375 \n",
      "Iteration = 1090, Losses: nd_expectation = 49319.484375 \n",
      "Iteration = 1100, Losses: nd_expectation = 49319.4765625 \n",
      "Iteration = 1110, Losses: nd_expectation = 49319.46484375 \n",
      "Iteration = 1120, Losses: nd_expectation = 49319.45703125 \n",
      "Iteration = 1130, Losses: nd_expectation = 49319.4453125 \n",
      "Iteration = 1140, Losses: nd_expectation = 49319.44140625 \n",
      "Iteration = 1150, Losses: nd_expectation = 49319.4296875 \n",
      "Iteration = 1160, Losses: nd_expectation = 49319.421875 \n",
      "Iteration = 1170, Losses: nd_expectation = 49319.4140625 \n",
      "Iteration = 1180, Losses: nd_expectation = 49319.40625 \n",
      "Iteration = 1190, Losses: nd_expectation = 49319.3984375 \n",
      "Iteration = 1200, Losses: nd_expectation = 49319.38671875 \n",
      "Iteration = 1210, Losses: nd_expectation = 49319.3828125 \n",
      "Iteration = 1220, Losses: nd_expectation = 49319.37109375 \n",
      "Iteration = 1230, Losses: nd_expectation = 49319.3671875 \n",
      "Iteration = 1240, Losses: nd_expectation = 49319.35546875 \n",
      "Iteration = 1250, Losses: nd_expectation = 49319.3515625 \n",
      "Iteration = 1260, Losses: nd_expectation = 49319.34375 \n",
      "Iteration = 1270, Losses: nd_expectation = 49319.3359375 \n",
      "Iteration = 1280, Losses: nd_expectation = 49319.328125 \n",
      "Iteration = 1290, Losses: nd_expectation = 49319.3203125 \n",
      "Iteration = 1300, Losses: nd_expectation = 49319.31640625 \n",
      "Iteration = 1310, Losses: nd_expectation = 49319.30859375 \n",
      "Iteration = 1320, Losses: nd_expectation = 49319.30078125 \n",
      "Iteration = 1330, Losses: nd_expectation = 49319.296875 \n",
      "Iteration = 1340, Losses: nd_expectation = 49319.2890625 \n",
      "Iteration = 1350, Losses: nd_expectation = 49319.28125 \n",
      "Iteration = 1360, Losses: nd_expectation = 49319.27734375 \n",
      "Iteration = 1370, Losses: nd_expectation = 49319.26953125 \n",
      "Iteration = 1380, Losses: nd_expectation = 49319.265625 \n",
      "Iteration = 1390, Losses: nd_expectation = 49319.26171875 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 1400, Losses: nd_expectation = 49319.25390625 \n",
      "Iteration = 1410, Losses: nd_expectation = 49319.24609375 \n",
      "Iteration = 1420, Losses: nd_expectation = 49319.24609375 \n",
      "Iteration = 1430, Losses: nd_expectation = 49319.23828125 \n",
      "Iteration = 1440, Losses: nd_expectation = 49319.234375 \n",
      "Iteration = 1450, Losses: nd_expectation = 49319.23046875 \n",
      "Iteration = 1460, Losses: nd_expectation = 49319.22265625 \n",
      "Iteration = 1470, Losses: nd_expectation = 49319.21875 \n",
      "Iteration = 1480, Losses: nd_expectation = 49319.21484375 \n",
      "Iteration = 1490, Losses: nd_expectation = 49319.2109375 \n",
      "Iteration = 1500, Losses: nd_expectation = 49319.2109375 \n",
      "Iteration = 1510, Losses: nd_expectation = 49319.203125 \n",
      "Iteration = 1520, Losses: nd_expectation = 49319.19921875 \n",
      "Iteration = 1530, Losses: nd_expectation = 49319.1953125 \n",
      "Iteration = 1540, Losses: nd_expectation = 49319.19140625 \n",
      "Iteration = 1550, Losses: nd_expectation = 49319.1875 \n",
      "Iteration = 1560, Losses: nd_expectation = 49319.1875 \n",
      "Iteration = 1570, Losses: nd_expectation = 49319.18359375 \n",
      "Iteration = 1580, Losses: nd_expectation = 49319.17578125 \n",
      "Iteration = 1590, Losses: nd_expectation = 49319.17578125 \n",
      "Iteration = 1600, Losses: nd_expectation = 49319.17578125 \n",
      "Iteration = 1610, Losses: nd_expectation = 49319.16796875 \n",
      "Iteration = 1620, Losses: nd_expectation = 49319.1640625 \n",
      "Iteration = 1630, Losses: nd_expectation = 49319.1640625 \n",
      "Iteration = 1640, Losses: nd_expectation = 49319.16015625 \n",
      "Iteration = 1650, Losses: nd_expectation = 49319.16015625 \n",
      "Iteration = 1660, Losses: nd_expectation = 49319.15625 \n",
      "Iteration = 1670, Losses: nd_expectation = 49319.15234375 \n",
      "Iteration = 1680, Losses: nd_expectation = 49319.1484375 \n",
      "Iteration = 1690, Losses: nd_expectation = 49319.1484375 \n",
      "Iteration = 1700, Losses: nd_expectation = 49319.14453125 \n",
      "Iteration = 1710, Losses: nd_expectation = 49319.140625 \n",
      "Iteration = 1720, Losses: nd_expectation = 49319.140625 \n",
      "Iteration = 1730, Losses: nd_expectation = 49319.140625 \n",
      "Iteration = 1740, Losses: nd_expectation = 49319.13671875 \n",
      "Iteration = 1750, Losses: nd_expectation = 49319.1328125 \n",
      "Iteration = 1760, Losses: nd_expectation = 49319.1328125 \n",
      "Iteration = 1770, Losses: nd_expectation = 49319.12890625 \n",
      "Iteration = 1780, Losses: nd_expectation = 49319.125 \n",
      "Iteration = 1790, Losses: nd_expectation = 49319.125 \n",
      "Iteration = 1800, Losses: nd_expectation = 49319.125 \n",
      "Iteration = 1810, Losses: nd_expectation = 49319.125 \n",
      "Iteration = 1820, Losses: nd_expectation = 49319.125 \n",
      "Iteration = 1830, Losses: nd_expectation = 49319.12109375 \n",
      "Iteration = 1840, Losses: nd_expectation = 49319.1171875 \n",
      "Iteration = 1850, Losses: nd_expectation = 49319.11328125 \n",
      "Iteration = 1860, Losses: nd_expectation = 49319.11328125 \n",
      "Iteration = 1870, Losses: nd_expectation = 49319.11328125 \n",
      "Iteration = 1880, Losses: nd_expectation = 49319.109375 \n",
      "Iteration = 1890, Losses: nd_expectation = 49319.109375 \n",
      "Iteration = 1900, Losses: nd_expectation = 49319.109375 \n",
      "Iteration = 1910, Losses: nd_expectation = 49319.10546875 \n",
      "Iteration = 1920, Losses: nd_expectation = 49319.10546875 \n",
      "Iteration = 1930, Losses: nd_expectation = 49319.10546875 \n",
      "Iteration = 1940, Losses: nd_expectation = 49319.10546875 \n",
      "Iteration = 1950, Losses: nd_expectation = 49319.1015625 \n",
      "Iteration = 1960, Losses: nd_expectation = 49319.1015625 \n",
      "Iteration = 1970, Losses: nd_expectation = 49319.09765625 \n",
      "Iteration = 1980, Losses: nd_expectation = 49319.09375 \n",
      "Iteration = 1990, Losses: nd_expectation = 49319.09375 \n",
      "Iteration = 2000, Losses: nd_expectation = 49319.09375 \n",
      "Iteration = 2010, Losses: nd_expectation = 49319.09375 \n",
      "Iteration = 2020, Losses: nd_expectation = 49319.08984375 \n",
      "Iteration = 2030, Losses: nd_expectation = 49319.08984375 \n",
      "Iteration = 2040, Losses: nd_expectation = 49319.08984375 \n",
      "Iteration = 2050, Losses: nd_expectation = 49319.08984375 \n",
      "Iteration = 2060, Losses: nd_expectation = 49319.08984375 \n",
      "Iteration = 2070, Losses: nd_expectation = 49319.0859375 \n",
      "Iteration = 2080, Losses: nd_expectation = 49319.0859375 \n",
      "Iteration = 2090, Losses: nd_expectation = 49319.08203125 \n",
      "Iteration = 2100, Losses: nd_expectation = 49319.0859375 \n",
      "Iteration = 2110, Losses: nd_expectation = 49319.08203125 \n",
      "Iteration = 2120, Losses: nd_expectation = 49319.08203125 \n",
      "Iteration = 2130, Losses: nd_expectation = 49319.08203125 \n",
      "Iteration = 2140, Losses: nd_expectation = 49319.078125 \n",
      "Iteration = 2150, Losses: nd_expectation = 49319.07421875 \n",
      "Iteration = 2160, Losses: nd_expectation = 49319.07421875 \n",
      "Iteration = 2170, Losses: nd_expectation = 49319.07421875 \n",
      "Iteration = 2180, Losses: nd_expectation = 49319.07421875 \n",
      "Iteration = 2190, Losses: nd_expectation = 49319.0703125 \n",
      "Iteration = 2200, Losses: nd_expectation = 49319.0703125 \n",
      "Iteration = 2210, Losses: nd_expectation = 49319.0703125 \n",
      "Iteration = 2220, Losses: nd_expectation = 49319.0703125 \n",
      "Iteration = 2230, Losses: nd_expectation = 49319.0703125 \n",
      "Iteration = 2240, Losses: nd_expectation = 49319.06640625 \n",
      "Iteration = 2250, Losses: nd_expectation = 49319.06640625 \n",
      "Iteration = 2260, Losses: nd_expectation = 49319.06640625 \n",
      "Iteration = 2270, Losses: nd_expectation = 49319.0625 \n",
      "Iteration = 2280, Losses: nd_expectation = 49319.06640625 \n",
      "Iteration = 2290, Losses: nd_expectation = 49319.0625 \n",
      "Iteration = 2300, Losses: nd_expectation = 49319.05859375 \n",
      "Iteration = 2310, Losses: nd_expectation = 49319.0625 \n",
      "Iteration = 2320, Losses: nd_expectation = 49319.05859375 \n",
      "Iteration = 2330, Losses: nd_expectation = 49319.05859375 \n",
      "Iteration = 2340, Losses: nd_expectation = 49319.05859375 \n",
      "Iteration = 2350, Losses: nd_expectation = 49319.05859375 \n",
      "Iteration = 2360, Losses: nd_expectation = 49319.0546875 \n",
      "Iteration = 2370, Losses: nd_expectation = 49319.0546875 \n",
      "Iteration = 2380, Losses: nd_expectation = 49319.0546875 \n",
      "Iteration = 2390, Losses: nd_expectation = 49319.0546875 \n",
      "Iteration = 2400, Losses: nd_expectation = 49319.0546875 \n",
      "Iteration = 2410, Losses: nd_expectation = 49319.0546875 \n",
      "Iteration = 2420, Losses: nd_expectation = 49319.0546875 \n",
      "Iteration = 2430, Losses: nd_expectation = 49319.05078125 \n",
      "Iteration = 2440, Losses: nd_expectation = 49319.05078125 \n",
      "Iteration = 2450, Losses: nd_expectation = 49319.05078125 \n",
      "Iteration = 2460, Losses: nd_expectation = 49319.05078125 \n",
      "Iteration = 2470, Losses: nd_expectation = 49319.046875 \n",
      "Iteration = 2480, Losses: nd_expectation = 49319.046875 \n",
      "Iteration = 2490, Losses: nd_expectation = 49319.046875 \n",
      "Iteration = 2500, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2510, Losses: nd_expectation = 49319.046875 \n",
      "Iteration = 2520, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2530, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2540, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2550, Losses: nd_expectation = 49319.04296875 \n",
      "Iteration = 2560, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2570, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2580, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2590, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2600, Losses: nd_expectation = 49319.0390625 \n",
      "Iteration = 2610, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2620, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2630, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2640, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2650, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2660, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2670, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2680, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2690, Losses: nd_expectation = 49319.03515625 \n",
      "Iteration = 2700, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 2710, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 2720, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 2730, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 2740, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 2750, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 2760, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 2770, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 2780, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 2790, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 2800, Losses: nd_expectation = 49319.03125 \n",
      "Iteration = 2810, Losses: nd_expectation = 49319.02734375 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 2820, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 2830, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 2840, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 2850, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 2860, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 2870, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 2880, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 2890, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 2900, Losses: nd_expectation = 49319.02734375 \n",
      "Iteration = 2910, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 2920, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 2930, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 2940, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 2950, Losses: nd_expectation = 49319.01953125 \n",
      "Iteration = 2960, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 2970, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 2980, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 2990, Losses: nd_expectation = 49319.0234375 \n",
      "Iteration = 3000, Losses: nd_expectation = 49319.0234375 \n",
      "Reconstrution Loss: 47806.57421875 \n",
      "\n",
      "Loss: 49319.0234375 \n",
      "\n",
      "Transpose: 0.003536132350564003 \n",
      "\n",
      "Distance to axis-aligned solution: 0.09904575485510528 \n",
      "\n",
      "Distance to optimal subspace): 3.8146972658470446e-07 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelIn = model_config.get_model()\n",
    "print('Reconstrution Loss:', metric_recon_loss(modelIn, loader),'\\n') # full batch loss\n",
    "print('Loss:', metric_loss(modelIn, loader),'\\n')\n",
    "print('Transpose:', metric_transpose_theorem(modelIn),'\\n') # how close encoder and decoder.T are \n",
    "print('Distance to axis-aligned solution:', metric_alignment(modelIn, data.eigvectors),'\\n') # alignment of decoder columns to ground truth eigenvectors\n",
    "print('Distance to optimal subspace):', metric_subspace(modelIn, data.eigvectors, data.eigs),'\\n')\n",
    "\n",
    "trained_model = train_models(data_loader=loader, train_itr=model_dict['train_itr'], metrics_dict=None, model_configs=model_config)\n",
    "\n",
    "modelIn = model_config.get_model()\n",
    "print('Reconstrution Loss:', metric_recon_loss(modelIn, loader),'\\n') # full batch loss\n",
    "print('Loss:', metric_loss(modelIn, loader),'\\n')\n",
    "print('Transpose:', metric_transpose_theorem(modelIn),'\\n') # how close encoder and decoder.T are \n",
    "print('Distance to axis-aligned solution:', metric_alignment(modelIn, data.eigvectors),'\\n') # alignment of decoder columns to ground truth eigenvectors\n",
    "print('Distance to optimal subspace):', metric_subspace(modelIn, data.eigvectors, data.eigs),'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c249c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2a5287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb84e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
